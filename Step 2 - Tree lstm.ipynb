{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import generate_batches\n",
    "from data import prepare_data\n",
    "from data import data_to_index\n",
    "from data import DEP_LABELS\n",
    "from data import random_batch\n",
    "\n",
    "from model.encoder import Encoder\n",
    "from model.decoder import Decoder_luong\n",
    "from model.tree_lstm import Tree_lstm\n",
    "\n",
    "from BLEU import BLEU\n",
    "\n",
    "from utils import time_since\n",
    "\n",
    "from evaluator import Evaluator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "#from validation import Evaluator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "MAX_LENGTH = 100\n",
    "DIR_FILES = 'data/translation/train/'\n",
    "DIR_RESULTS = 'results/step_1'\n",
    "SPLIT_TRAIN = 0.7\n",
    "SPLIT_VALID = 0.15\n",
    "# The rest is for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 115244 sentence pairs\n",
      "Filtered to 83374 pairs\n",
      "Creating vocab...\n",
      "Creating trees...\n",
      "Indexed 12248 words in input language, 22537 words in output\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, input_trees, _, pairs = prepare_data('eng', 'esp', dir=DIR_FILES, return_trees=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_train = np.array(pairs[:60000])\n",
    "pairs_test = np.array(pairs[60000:])\n",
    "\n",
    "trees_train = np.array(input_trees[:60000])\n",
    "trees_test = np.array(input_trees[60000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_batches, target_batches, input_tree,\\\n",
    "          encoder, decoder, tree, criterion, batch_ix, train=True):\n",
    "    \n",
    "    if train and (batch_ix % batch_size) == 0:\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        tree_optimizer.zero_grad()\n",
    "        \n",
    "    loss = 0\n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden(1)\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, encoder_hidden)\n",
    "\n",
    "    state, tree_hidden = tree(input_tree[0], encoder_outputs)\n",
    "    encoder_outputs = torch.cat((encoder_outputs, state.unsqueeze(0)))\n",
    "    #print(encoder_outputs.shape, state.shape)\n",
    "    \n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))   \n",
    "    decoder_hidden = torch.cat((encoder_hidden, tree_hidden.unsqueeze(0)))\n",
    "    #decoder_hidden = encoder_hidden\n",
    "    # set the start of the sentences of the batch\n",
    "    decoder_input = torch.LongTensor([input_lang.vocab.stoi['<sos>']] * 1)\n",
    "\n",
    "    # store the decoder outputs to estimate the loss\n",
    "    all_decoder_outputs = Variable(torch.zeros(target_batches.size()[0], 1, len(output_lang.vocab.stoi)))\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "        decoder_context = decoder_context.cuda()  \n",
    "    \n",
    "    if train:\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    else:\n",
    "        use_teacher_forcing = False\n",
    "    \n",
    "    if use_teacher_forcing:        \n",
    "        # Use targets as inputs\n",
    "        for di in range(target_batches.shape[0]):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input.unsqueeze(0), decoder_context, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            decoder_input = target_batches[di]\n",
    "    else:        \n",
    "        # Use decoder output as inputs\n",
    "        for di in range(target_batches.shape[0]): \n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input.unsqueeze(0), decoder_context, decoder_hidden, encoder_outputs) \n",
    "            \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            \n",
    "            # Greedy approach, take the word with highest probability\n",
    "            topv, topi = decoder_output.data.topk(1)            \n",
    "            decoder_input = Variable(torch.LongTensor(topi.cpu()).squeeze(dim=0))\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    loss = nn.NLLLoss()(all_decoder_outputs.view(-1, decoder.output_size), target_batches.contiguous().view(-1))          \n",
    "    \n",
    "    if train and (batch_ix % batch_size) == 0:\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(tree.parameters(), clip)\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        tree_optimizer.step()\n",
    "    elif train:\n",
    "        loss.backward()\n",
    "    \n",
    "    return loss.item() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 512\n",
    "emb_size = 300\n",
    "n_layers = 2\n",
    "dropout_p = 0.1\n",
    "seed = 12\n",
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len(input_lang.vocab.stoi), hidden_size, emb_size, n_layers, dropout_p, input_lang, USE_CUDA)\n",
    "decoder = Decoder_luong(attn_model, hidden_size, len(output_lang.vocab.stoi), emb_size, 2 * n_layers + 1, dropout_p, output_lang, USE_CUDA)\n",
    "tree = Tree_lstm(hidden_size, hidden_size)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    tree = tree.cuda()\n",
    "    \n",
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, encoder.parameters()), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, decoder.parameters()), lr=learning_rate)\n",
    "tree_optimizer = optim.Adam(tree.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "validation_bleu = []\n",
    "\n",
    "plot_every = 5\n",
    "print_every = 5\n",
    "validate_loss_every = 25\n",
    "best_bleu = 0\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 36s (- 30m 36s) (1 1%) 8.9360\n",
      "2m 57s (- 56m 18s) (1 2%) 7.9924\n",
      "4m 16s (- 81m 5s) (1 3%) 7.6602\n",
      "5m 41s (- 108m 13s) (1 4%) 7.3888\n",
      "7m 5s (- 134m 44s) (1 5%) 7.2123\n",
      "8m 30s (- 161m 44s) (1 6%) 7.4825\n",
      "9m 53s (- 187m 54s) (1 7%) 7.4259\n",
      "11m 21s (- 215m 49s) (1 8%) 7.1312\n",
      "12m 45s (- 242m 23s) (1 9%) 6.9250\n",
      "14m 11s (- 269m 29s) (1 10%) 6.8648\n",
      "15m 34s (- 295m 49s) (1 11%) 6.9617\n",
      "16m 58s (- 322m 37s) (1 12%) 6.9180\n",
      "18m 24s (- 349m 40s) (1 13%) 6.8046\n",
      "19m 48s (- 376m 19s) (1 14%) 7.1147\n",
      "21m 9s (- 401m 57s) (1 16%) 8.0596\n",
      "22m 33s (- 428m 38s) (1 17%) 6.7547\n",
      "23m 58s (- 455m 38s) (1 18%) 6.7011\n",
      "25m 23s (- 482m 21s) (1 19%) 6.8869\n",
      "26m 50s (- 510m 6s) (1 20%) 6.8017\n",
      "28m 17s (- 537m 38s) (1 21%) 6.7670\n",
      "29m 42s (- 564m 33s) (1 22%) 6.6528\n",
      "31m 5s (- 590m 52s) (1 23%) 6.9381\n",
      "32m 35s (- 619m 16s) (1 24%) 7.6222\n",
      "34m 0s (- 646m 10s) (1 25%) 7.8320\n",
      "35m 26s (- 673m 32s) (1 26%) 7.0296\n",
      "36m 51s (- 700m 24s) (1 27%) 6.9229\n",
      "38m 21s (- 728m 53s) (1 28%) 6.8373\n",
      "39m 48s (- 756m 22s) (1 29%) 6.5892\n",
      "41m 15s (- 784m 2s) (1 30%) 6.5309\n",
      "42m 43s (- 811m 50s) (1 32%) 6.4942\n",
      "44m 13s (- 840m 19s) (1 33%) 6.3243\n",
      "45m 39s (- 867m 38s) (1 34%) 6.6012\n",
      "47m 6s (- 894m 57s) (1 35%) 6.4429\n",
      "48m 24s (- 919m 47s) (1 36%) 6.4649\n",
      "49m 40s (- 943m 45s) (1 37%) 6.8361\n",
      "50m 59s (- 968m 52s) (1 38%) 6.4942\n",
      "52m 15s (- 992m 53s) (1 39%) 6.6595\n",
      "53m 38s (- 1019m 13s) (1 40%) 6.2775\n",
      "54m 56s (- 1043m 56s) (1 41%) 6.3294\n",
      "56m 15s (- 1068m 53s) (1 42%) 6.3333\n",
      "57m 33s (- 1093m 42s) (1 43%) 6.4001\n",
      "58m 52s (- 1118m 43s) (1 44%) 6.5771\n",
      "60m 13s (- 1144m 16s) (1 45%) 6.3862\n",
      "61m 31s (- 1169m 1s) (1 46%) 6.2430\n",
      "62m 51s (- 1194m 14s) (1 48%) 6.1837\n",
      "64m 9s (- 1219m 4s) (1 49%) 6.2106\n",
      "65m 28s (- 1244m 9s) (1 50%) 6.1364\n",
      "66m 48s (- 1269m 24s) (1 51%) 6.3455\n",
      "68m 9s (- 1294m 52s) (1 52%) 6.4452\n",
      "69m 32s (- 1321m 21s) (1 53%) 6.3446\n",
      "70m 57s (- 1348m 18s) (1 54%) 6.4582\n",
      "72m 20s (- 1374m 35s) (1 55%) 6.5688\n",
      "73m 46s (- 1401m 35s) (1 56%) 6.5400\n",
      "75m 8s (- 1427m 47s) (1 57%) 6.2057\n",
      "76m 27s (- 1452m 39s) (1 58%) 6.2760\n",
      "77m 48s (- 1478m 30s) (1 59%) 6.7039\n",
      "79m 14s (- 1505m 27s) (1 60%) 6.6267\n",
      "80m 40s (- 1532m 46s) (1 61%) 6.5674\n",
      "82m 16s (- 1563m 18s) (1 62%) 6.1680\n",
      "83m 50s (- 1593m 3s) (1 64%) 6.0805\n",
      "85m 24s (- 1622m 48s) (1 65%) 6.1942\n",
      "86m 54s (- 1651m 10s) (1 66%) 6.1981\n",
      "88m 25s (- 1680m 4s) (1 67%) 6.2532\n",
      "89m 59s (- 1709m 50s) (1 68%) 6.1550\n",
      "91m 29s (- 1738m 13s) (1 69%) 6.0744\n",
      "93m 2s (- 1767m 53s) (1 70%) 6.1035\n",
      "94m 34s (- 1797m 3s) (1 71%) 6.1113\n",
      "96m 7s (- 1826m 29s) (1 72%) 6.1145\n",
      "97m 38s (- 1855m 18s) (1 73%) 6.2361\n",
      "99m 10s (- 1884m 12s) (1 74%) 6.1585\n",
      "100m 40s (- 1912m 46s) (1 75%) 6.1446\n",
      "102m 6s (- 1940m 9s) (1 76%) 6.0126\n",
      "103m 35s (- 1968m 17s) (1 77%) 6.1823\n",
      "105m 9s (- 1998m 2s) (1 78%) 6.0902\n",
      "106m 42s (- 2027m 19s) (1 80%) 6.1259\n",
      "108m 14s (- 2056m 27s) (1 81%) 6.0278\n",
      "109m 48s (- 2086m 17s) (1 82%) 6.1008\n",
      "111m 20s (- 2115m 24s) (1 83%) 6.1405\n",
      "112m 47s (- 2142m 57s) (1 84%) 6.1079\n",
      "114m 22s (- 2173m 14s) (1 85%) 6.0849\n",
      "115m 58s (- 2203m 29s) (1 86%) 5.9932\n",
      "117m 29s (- 2232m 28s) (1 87%) 6.0322\n",
      "119m 2s (- 2261m 43s) (1 88%) 6.1296\n",
      "120m 36s (- 2291m 39s) (1 89%) 6.3911\n",
      "122m 12s (- 2321m 54s) (1 90%) 6.3159\n",
      "123m 52s (- 2353m 33s) (1 91%) 6.4748\n",
      "125m 28s (- 2383m 53s) (1 92%) 6.2232\n",
      "126m 59s (- 2412m 41s) (1 93%) 6.1864\n",
      "128m 32s (- 2442m 9s) (1 94%) 6.0974\n",
      "130m 7s (- 2472m 16s) (1 96%) 6.0785\n",
      "131m 43s (- 2502m 41s) (1 97%) 6.1289\n",
      "133m 22s (- 2533m 59s) (1 98%) 6.2586\n",
      "134m 56s (- 2563m 47s) (1 99%) 6.5041\n",
      "val_loss: 7.3158 - bleu: 0\n",
      "168m 41s (- 1518m 10s) (2 1%) 273.1829\n",
      "170m 23s (- 1533m 35s) (2 2%) 6.0893\n",
      "171m 58s (- 1547m 50s) (2 3%) 5.9257\n",
      "173m 40s (- 1563m 1s) (2 4%) 6.2050\n",
      "175m 26s (- 1578m 56s) (2 5%) 6.1333\n",
      "177m 11s (- 1594m 45s) (2 6%) 5.9562\n",
      "178m 51s (- 1609m 44s) (2 7%) 5.8435\n",
      "180m 31s (- 1624m 47s) (2 8%) 5.9090\n",
      "182m 13s (- 1640m 3s) (2 9%) 5.8664\n",
      "183m 55s (- 1655m 15s) (2 10%) 5.8640\n",
      "185m 37s (- 1670m 36s) (2 11%) 5.7777\n",
      "187m 21s (- 1686m 14s) (2 12%) 5.8958\n",
      "189m 7s (- 1702m 9s) (2 13%) 5.8347\n",
      "190m 52s (- 1717m 52s) (2 14%) 5.7199\n",
      "192m 34s (- 1733m 10s) (2 16%) 5.9239\n",
      "194m 21s (- 1749m 16s) (2 17%) 6.1312\n",
      "196m 4s (- 1764m 38s) (2 18%) 5.9451\n",
      "197m 50s (- 1780m 35s) (2 19%) 5.9201\n",
      "199m 38s (- 1796m 42s) (2 20%) 5.8290\n",
      "201m 21s (- 1812m 13s) (2 21%) 5.6865\n",
      "203m 5s (- 1827m 50s) (2 22%) 5.8705\n",
      "204m 50s (- 1843m 38s) (2 23%) 5.9708\n",
      "206m 31s (- 1858m 47s) (2 24%) 6.2278\n",
      "208m 7s (- 1873m 7s) (2 25%) 5.9487\n",
      "209m 49s (- 1888m 21s) (2 26%) 6.1555\n",
      "211m 32s (- 1903m 51s) (2 27%) 6.0680\n",
      "213m 14s (- 1919m 10s) (2 28%) 6.0858\n",
      "215m 0s (- 1935m 3s) (2 29%) 6.0789\n",
      "216m 41s (- 1950m 17s) (2 30%) 5.9037\n",
      "218m 26s (- 1966m 1s) (2 32%) 5.8405\n",
      "220m 9s (- 1981m 27s) (2 33%) 5.8709\n",
      "221m 47s (- 1996m 10s) (2 34%) 6.0490\n",
      "223m 26s (- 2010m 54s) (2 35%) 6.0557\n",
      "224m 58s (- 2024m 49s) (2 36%) 5.9129\n",
      "226m 37s (- 2039m 40s) (2 37%) 5.8298\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs): \n",
    "    # Shuffle data\n",
    "    #id_aux = np.random.permutation(np.arange(len(pairs_train)))\n",
    "    #pairs_train = pairs_train[id_aux]\n",
    "    \n",
    "    # Get the batches for this epoch\n",
    "    input_batches, input_trees, target_batches = generate_batches(input_lang, output_lang, 1, pairs_train, arr_dep=trees_train, USE_CUDA=USE_CUDA)    \n",
    "    \n",
    "    for batch_ix, (input_batch, input_tree, target_var) in enumerate(zip(input_batches, input_trees, target_batches)):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        tree.train()\n",
    "        \n",
    "        #[input_var, _, _, _, _, _, _, _] = input_batch\n",
    "        input_var = input_batch\n",
    "\n",
    "        # Run the train function\n",
    "        loss = train(input_var, target_var, input_tree,\\\n",
    "                 encoder, decoder, tree, criterion, batch_ix, train=True)\n",
    "        #loss = train_luong(input_var, target_var, input_var.size(1), True)\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Keep track of loss\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if batch_ix == 0: continue            \n",
    "\n",
    "        if batch_ix % (print_every * batch_size) == 0:\n",
    "            print_loss_avg = print_loss_total / (print_every * batch_size)\n",
    "            print_loss_total = 0\n",
    "            print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, batch_ix / len(input_batches) * 100, print_loss_avg)\n",
    "            train_losses.append(loss)\n",
    "            print(print_summary)\n",
    "    \n",
    "    input_batches, input_trees, target_batches = generate_batches(input_lang, output_lang, 1, pairs_test, arr_dep=trees_test, USE_CUDA=USE_CUDA)\n",
    "    print_loss_total = 0\n",
    "    for batch_ix, (input_batch, input_tree, target_var) in enumerate(zip(input_batches, input_trees, target_batches)):\n",
    "    \n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        tree.eval()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            #[input_var, _, _, _, _, _, _, _] = input_batch\n",
    "            input_var = input_batch\n",
    "            # Run the train function\n",
    "            loss = train(input_var, target_var, input_tree,\\\n",
    "                     encoder, decoder, tree, criterion, batch_ix, train=False)\n",
    "\n",
    "            print_loss_total += loss\n",
    "            del loss\n",
    "            torch.cuda.empty_cache()\n",
    "    val_loss = print_loss_total / len(input_batches)\n",
    "    validation_losses.append(val_loss)\n",
    "    # Evaluating Bleu\n",
    "    #evaluator = Evaluator(encoder, decoder, input_lang, output_lang, MAX_LENGTH, True)\n",
    "    #candidates, references = evaluator.get_candidates_and_references(pairs_test, k_beams=1)\n",
    "    #bleu = BLEU(candidates, [references])\n",
    "    #if bleu[0] > best_bleu:\n",
    "    #    best_bleu = bleu[0]\n",
    "    #    torch.save(encoder.state_dict(), f'{DIR_RESULTS}/encoder.pkl')\n",
    "    #    torch.save(decoder.state_dict(), f'{DIR_RESULTS}/decoder.pkl')\n",
    "    #validation_bleu.append(bleu)\n",
    "    print(f'val_loss: {val_loss:.4f} - bleu: {0}')\n",
    "\n",
    "    # Prevent overflow gpu memory\n",
    "    #del evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(encoder, decoder, input_lang, output_lang, \n",
    "                      MAX_LENGTH, USE_CUDA)\n",
    "candidates, references = evaluator.get_candidates_and_references(pairs_test[:10000], k_beams=2)\n",
    "len(candidates), len(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28063523097173265,\n",
       " [0.6573135078342698,\n",
       "  0.37567686039915427,\n",
       "  0.22488307382629802,\n",
       "  0.13494545201862276],\n",
       " 0.953820572858132)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEU(candidates, [references]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.041672706604004,\n",
       " 7.149496555328369,\n",
       " 14.810012817382812,\n",
       " 12.101698875427246,\n",
       " 9.06682014465332,\n",
       " 7.260944366455078,\n",
       " 6.044005393981934,\n",
       " 6.0010833740234375,\n",
       " 7.1673264503479,\n",
       " 6.06639289855957,\n",
       " 6.229933261871338,\n",
       " 8.623738288879395,\n",
       " 5.882908344268799,\n",
       " 4.927737236022949,\n",
       " 5.671040058135986,\n",
       " 7.489520072937012,\n",
       " 5.501565456390381,\n",
       " 5.914140224456787,\n",
       " 6.912267208099365,\n",
       " 6.224165916442871,\n",
       " 7.6937079429626465,\n",
       " 6.377658843994141,\n",
       " 8.010522842407227,\n",
       " 8.193879127502441,\n",
       " 7.284544944763184,\n",
       " 4.864162445068359,\n",
       " 6.447579860687256,\n",
       " 6.805881977081299,\n",
       " 5.03970193862915,\n",
       " 6.144567012786865,\n",
       " 5.522188186645508,\n",
       " 6.3946533203125,\n",
       " 7.317024230957031,\n",
       " 7.084739685058594,\n",
       " 4.866414546966553,\n",
       " 4.8789286613464355,\n",
       " 6.360021114349365,\n",
       " 5.258521556854248,\n",
       " 7.594843864440918,\n",
       " 5.99109411239624,\n",
       " 6.1218085289001465,\n",
       " 4.6263885498046875,\n",
       " 6.505831241607666,\n",
       " 6.49678897857666,\n",
       " 6.661844253540039,\n",
       " 5.703457832336426,\n",
       " 6.080120086669922,\n",
       " 5.556210994720459,\n",
       " 4.3718485832214355,\n",
       " 7.616245269775391,\n",
       " 5.660667896270752,\n",
       " 4.477021217346191,\n",
       " 5.971453666687012,\n",
       " 7.151060581207275,\n",
       " 7.284686088562012,\n",
       " 4.710358619689941,\n",
       " 5.699878692626953,\n",
       " 5.8283185958862305,\n",
       " 5.429839134216309,\n",
       " 5.627746105194092,\n",
       " 8.024958610534668,\n",
       " 7.326678276062012,\n",
       " 6.238666534423828,\n",
       " 4.728693962097168,\n",
       " 6.361328125,\n",
       " 5.92225456237793,\n",
       " 6.291927337646484,\n",
       " 6.011835098266602,\n",
       " 7.155662536621094,\n",
       " 5.337331295013428,\n",
       " 7.359513282775879,\n",
       " 6.708942890167236,\n",
       " 6.291254997253418,\n",
       " 6.5870819091796875,\n",
       " 6.9649858474731445,\n",
       " 5.453511714935303,\n",
       " 5.605909824371338,\n",
       " 6.4293036460876465,\n",
       " 6.750390529632568,\n",
       " 8.476428031921387,\n",
       " 5.792107582092285,\n",
       " 7.52388334274292,\n",
       " 5.88793420791626,\n",
       " 5.64914083480835,\n",
       " 5.583569049835205,\n",
       " 7.05214786529541,\n",
       " 7.007693767547607,\n",
       " 6.556692600250244,\n",
       " 5.914644241333008,\n",
       " 7.384115219116211,\n",
       " 6.446426868438721,\n",
       " 5.6869215965271,\n",
       " 6.317768573760986,\n",
       " 6.537539958953857,\n",
       " 8.257403373718262,\n",
       " 6.223647594451904,\n",
       " 7.760086536407471,\n",
       " 6.339871883392334,\n",
       " 6.288576602935791,\n",
       " 6.117007732391357,\n",
       " 4.761729717254639,\n",
       " 5.098626136779785,\n",
       " 5.2466816902160645,\n",
       " 4.348966121673584,\n",
       " 6.218953609466553,\n",
       " 4.525362968444824,\n",
       " 8.28030014038086,\n",
       " 5.524833679199219,\n",
       " 7.029933452606201,\n",
       " 5.692931175231934,\n",
       " 5.107240200042725,\n",
       " 7.430395126342773,\n",
       " 6.536320686340332,\n",
       " 6.89471960067749,\n",
       " 4.141633987426758,\n",
       " 5.832042217254639,\n",
       " 5.386961460113525,\n",
       " 5.803618907928467,\n",
       " 6.419718265533447,\n",
       " 6.172667503356934,\n",
       " 7.619015216827393,\n",
       " 6.166060447692871,\n",
       " 6.7607011795043945,\n",
       " 5.820564270019531,\n",
       " 6.111392021179199,\n",
       " 4.593202114105225,\n",
       " 6.3956732749938965,\n",
       " 4.5033745765686035,\n",
       " 5.831901550292969,\n",
       " 6.683056354522705,\n",
       " 6.531650543212891,\n",
       " 4.357241630554199,\n",
       " 6.526559829711914,\n",
       " 5.965932369232178,\n",
       " 7.174294948577881,\n",
       " 5.76188325881958,\n",
       " 5.928871154785156,\n",
       " 6.473082542419434,\n",
       " 6.172927379608154,\n",
       " 6.565548896789551]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"tom wasn 't convinced it was a good idea .\",\n",
       "       'tom no estaba convencido de que fuera una buena idea .'],\n",
       "      dtype='<U245')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_test[480]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['just act as if nothing has happened .',\n",
       "       'haga de cuenta que nada ha ocurrido .'],\n",
       "      dtype='<U245')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_train[80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
