{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import generate_batches\n",
    "from data import prepare_data\n",
    "from data import data_to_index\n",
    "from data import DEP_LABELS\n",
    "from data import random_batch\n",
    "\n",
    "from model.encoder import Encoder\n",
    "from model.decoder import Decoder_luong\n",
    "#from model.tree_lstm import Tree_lstm\n",
    "\n",
    "from BLEU import BLEU\n",
    "\n",
    "from utils import time_since\n",
    "\n",
    "from evaluator import Evaluator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "#from validation import Evaluator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Child sum tree lstm\n",
    "class Tree_lstm(nn.Module):\n",
    "    def __init__(self, in_dim, mem_dim):\n",
    "        super(Tree_lstm, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.mem_dim = mem_dim\n",
    "        self.ioux = nn.Linear(self.in_dim, 3 * self.mem_dim)\n",
    "        self.iouh = nn.Linear(self.mem_dim, 3 * self.mem_dim)\n",
    "        self.fx = nn.Linear(self.in_dim, self.mem_dim)\n",
    "        self.fh = nn.Linear(self.mem_dim, self.mem_dim)\n",
    "\n",
    "    def node_forward(self, inputs, child_c, child_h):\n",
    "        child_h_sum = torch.sum(child_h, dim=0, keepdim=True)\n",
    "\n",
    "        iou = self.ioux(inputs) + self.iouh(child_h_sum)\n",
    "        i, o, u = torch.split(iou, iou.size(1) // 3, dim=1)\n",
    "        i, o, u = F.sigmoid(i), F.sigmoid(o), F.tanh(u)\n",
    "\n",
    "        f = F.sigmoid(\n",
    "            self.fh(child_h) +\n",
    "            self.fx(inputs).repeat(len(child_h), 1)\n",
    "        )\n",
    "        fc = torch.mul(f, child_c)\n",
    "\n",
    "        c = torch.mul(i, u) + torch.sum(fc, dim=0, keepdim=True)\n",
    "        h = torch.mul(o, F.tanh(c))\n",
    "        return c, h\n",
    "\n",
    "    def forward(self, tree, inputs):\n",
    "        tree_acum = None\n",
    "        for idx in range(tree.num_children):\n",
    "            tree_acum = self.forward(tree.children[idx], inputs)\n",
    "        \n",
    "        if tree.num_children == 0:\n",
    "            child_c = inputs[0].detach().new(1, self.mem_dim).fill_(0.).requires_grad_()\n",
    "            child_h = inputs[0].detach().new(1, self.mem_dim).fill_(0.).requires_grad_()\n",
    "        else:\n",
    "            child_c, child_h = zip(* map(lambda x: x.state, tree.children))\n",
    "            child_c, child_h = torch.cat(child_c, dim=0), torch.cat(child_h, dim=0)\n",
    "        \n",
    "        tree.state = self.node_forward(inputs[tree.idx - 1], child_c, child_h)\n",
    "        if tree_acum:\n",
    "            s, h = torch.cat((tree_acum[0], tree.state[0])), tree.state[1]\n",
    "        else:\n",
    "            s, h = tree.state\n",
    "        return s, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = False\n",
    "MAX_LENGTH = 100\n",
    "DIR_FILES = 'data/translation/train/'\n",
    "DIR_RESULTS = 'results/step_1'\n",
    "SPLIT_TRAIN = 0.7\n",
    "SPLIT_VALID = 0.15\n",
    "SEED = 12\n",
    "# The rest is for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 115244 sentence pairs\n",
      "Filtered to 84144 pairs\n",
      "Creating vocab...\n",
      "Creating trees...\n",
      "Indexed 12330 words in input language, 21913 words in output\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, trees, _, pairs = prepare_data('eng', 'esp', dir=DIR_FILES, return_trees=True, output_tree='tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_train = np.array(pairs[:60000])\n",
    "pairs_test = np.array(pairs[60000:])\n",
    "\n",
    "trees_train = np.array(trees[:60000])\n",
    "trees_test = np.array(trees[60000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_batches, target_batches, input_tree,\\\n",
    "          encoder, decoder, tree, criterion, batch_ix, train=True):\n",
    "    \n",
    "    if train and (batch_ix % batch_size) == 0:\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        tree_optimizer.zero_grad()\n",
    "        \n",
    "    loss = 0\n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden(1)\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, encoder_hidden)\n",
    "\n",
    "    state, tree_hidden = tree(input_tree[0], encoder_outputs)\n",
    "    #encoder_outputs = torch.cat((encoder_outputs, state.unsqueeze(1)))\n",
    "    #print(encoder_outputs.shape, state.shape)\n",
    "\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))   \n",
    "    decoder_hidden = torch.cat((encoder_hidden, tree_hidden.unsqueeze(1)))\n",
    "    #decoder_hidden = encoder_hidden\n",
    "    # set the start of the sentences of the batch\n",
    "    decoder_input = torch.LongTensor([input_lang.vocab.stoi['<sos>']] * 1)\n",
    "\n",
    "    # store the decoder outputs to estimate the loss\n",
    "    all_decoder_outputs = Variable(torch.zeros(target_batches.size()[0], 1, len(output_lang.vocab.stoi)))\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "        decoder_context = decoder_context.cuda()  \n",
    "    \n",
    "    if train:\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    else:\n",
    "        use_teacher_forcing = False\n",
    "    \n",
    "    if use_teacher_forcing:        \n",
    "        # Use targets as inputs\n",
    "        for di in range(target_batches.shape[0]):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input.unsqueeze(0), decoder_context, decoder_hidden, state.unsqueeze(1))\n",
    "            \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            decoder_input = target_batches[di]\n",
    "    else:        \n",
    "        # Use decoder output as inputs\n",
    "        for di in range(target_batches.shape[0]): \n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input.unsqueeze(0), decoder_context, decoder_hidden, encoder_outputs) \n",
    "            \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            \n",
    "            # Greedy approach, take the word with highest probability\n",
    "            topv, topi = decoder_output.data.topk(1)            \n",
    "            decoder_input = Variable(torch.LongTensor(topi.cpu()).squeeze(dim=0))\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    loss = nn.NLLLoss()(all_decoder_outputs.view(-1, decoder.output_size), target_batches.contiguous().view(-1))          \n",
    "    \n",
    "    if train and (batch_ix % batch_size) == 0:\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(tree.parameters(), clip)\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        tree_optimizer.step()\n",
    "    elif train:\n",
    "        loss.backward()\n",
    "    else:\n",
    "        del all_decoder_outputs\n",
    "        del encoder_outputs\n",
    "        del decoder_hidden\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return loss.data[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 512\n",
    "emb_size = 300\n",
    "n_layers = 2\n",
    "dropout_p = 0.1\n",
    "seed = 12\n",
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len(input_lang.vocab.stoi), hidden_size, emb_size, n_layers, dropout_p, input_lang, USE_CUDA)\n",
    "decoder = Decoder_luong(attn_model, hidden_size, len(output_lang.vocab.stoi), emb_size, 2 * n_layers + 1, dropout_p, output_lang, USE_CUDA)\n",
    "tree = Tree_lstm(hidden_size, hidden_size)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    tree = tree.cuda()\n",
    "    \n",
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, encoder.parameters()), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, decoder.parameters()), lr=learning_rate)\n",
    "tree_optimizer = optim.Adam(tree.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "validation_bleu = []\n",
    "\n",
    "plot_every = 5\n",
    "print_every = 5\n",
    "validate_loss_every = 25\n",
    "best_bleu = 0\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krivas/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/krivas/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/krivas/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:75: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 29s (- 788m 0s) (1 1%) 10.6012\n",
      "16m 51s (- 773m 42s) (1 2%) 9.7603\n",
      "25m 6s (- 759m 29s) (1 3%) 8.4353\n",
      "33m 19s (- 747m 46s) (1 4%) 7.8625\n",
      "41m 35s (- 738m 16s) (1 5%) 7.5292\n",
      "49m 55s (- 730m 13s) (1 6%) 7.3399\n",
      "58m 11s (- 721m 4s) (1 7%) 7.4719\n",
      "66m 28s (- 712m 26s) (1 8%) 6.9598\n",
      "74m 45s (- 704m 2s) (1 9%) 6.9772\n",
      "83m 3s (- 695m 37s) (1 10%) 6.9301\n",
      "91m 21s (- 687m 14s) (1 11%) 6.6995\n",
      "99m 45s (- 679m 37s) (1 12%) 6.6602\n",
      "108m 0s (- 670m 54s) (1 13%) 6.5613\n",
      "116m 21s (- 662m 47s) (1 14%) 6.6700\n",
      "124m 39s (- 654m 27s) (1 16%) 6.5733\n",
      "133m 5s (- 646m 45s) (1 17%) 6.5083\n",
      "141m 21s (- 638m 9s) (1 18%) 6.4577\n",
      "149m 42s (- 630m 1s) (1 19%) 6.4039\n",
      "157m 59s (- 621m 33s) (1 20%) 6.3379\n",
      "166m 11s (- 612m 50s) (1 21%) 6.3627\n",
      "174m 27s (- 604m 23s) (1 22%) 6.5350\n",
      "182m 42s (- 595m 52s) (1 23%) 6.3417\n",
      "190m 58s (- 587m 26s) (1 24%) 6.2699\n",
      "199m 17s (- 579m 11s) (1 25%) 6.2754\n",
      "207m 36s (- 570m 56s) (1 26%) 6.2305\n",
      "215m 54s (- 562m 36s) (1 27%) 6.2024\n",
      "224m 14s (- 554m 22s) (1 28%) 6.1223\n",
      "232m 33s (- 546m 6s) (1 29%) 6.1847\n",
      "240m 58s (- 538m 1s) (1 30%) 6.2269\n",
      "249m 19s (- 529m 48s) (1 32%) 6.2991\n",
      "257m 36s (- 521m 27s) (1 33%) 6.2501\n",
      "265m 54s (- 513m 7s) (1 34%) 6.2048\n",
      "274m 15s (- 504m 53s) (1 35%) 6.2405\n",
      "282m 32s (- 496m 31s) (1 36%) 6.3648\n",
      "290m 53s (- 488m 16s) (1 37%) 6.5642\n",
      "299m 9s (- 479m 53s) (1 38%) 6.4461\n",
      "307m 23s (- 471m 28s) (1 39%) 6.2076\n",
      "315m 38s (- 463m 4s) (1 40%) 6.3024\n",
      "323m 53s (- 454m 42s) (1 41%) 6.0648\n",
      "332m 13s (- 446m 26s) (1 42%) 6.2795\n",
      "340m 32s (- 438m 8s) (1 43%) 6.1058\n",
      "348m 52s (- 429m 51s) (1 44%) 6.2191\n",
      "357m 7s (- 421m 28s) (1 45%) 6.0136\n",
      "365m 23s (- 413m 8s) (1 46%) 6.1396\n",
      "373m 47s (- 404m 56s) (1 48%) 6.2363\n",
      "381m 58s (- 396m 30s) (1 49%) 6.0394\n",
      "390m 15s (- 388m 10s) (1 50%) 6.0171\n",
      "398m 31s (- 379m 50s) (1 51%) 6.1103\n",
      "406m 46s (- 371m 29s) (1 52%) 6.0147\n",
      "415m 0s (- 363m 7s) (1 53%) 6.0470\n",
      "423m 15s (- 354m 47s) (1 54%) 5.9688\n",
      "431m 37s (- 346m 33s) (1 55%) 6.0325\n",
      "439m 56s (- 338m 15s) (1 56%) 5.9281\n",
      "448m 12s (- 329m 56s) (1 57%) 5.8466\n",
      "456m 30s (- 321m 37s) (1 58%) 5.9205\n",
      "464m 49s (- 313m 20s) (1 59%) 5.9284\n",
      "473m 9s (- 305m 3s) (1 60%) 5.8847\n",
      "481m 26s (- 296m 44s) (1 61%) 5.9398\n",
      "489m 37s (- 288m 22s) (1 62%) 5.7573\n",
      "497m 54s (- 280m 4s) (1 64%) 5.9214\n",
      "506m 13s (- 271m 47s) (1 65%) 5.9060\n",
      "514m 30s (- 263m 28s) (1 66%) 6.0359\n",
      "522m 46s (- 255m 9s) (1 67%) 6.0750\n",
      "531m 6s (- 246m 52s) (1 68%) 5.9550\n",
      "539m 23s (- 238m 34s) (1 69%) 5.8300\n",
      "547m 38s (- 230m 15s) (1 70%) 5.8122\n",
      "555m 51s (- 221m 55s) (1 71%) 5.8445\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs): \n",
    "    # Shuffle data\n",
    "    #id_aux = np.random.permutation(np.arange(len(pairs_train)))\n",
    "    #pairs_train = pairs_train[id_aux]\n",
    "    \n",
    "    tree.train()\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    # Get the batches for this epoch\n",
    "    input_batches, input_trees, target_batches = generate_batches(input_lang, output_lang, 1, pairs_train, arr_dep=trees_train, USE_CUDA=USE_CUDA)    \n",
    "    print_loss_total = 0\n",
    "    for batch_ix, (input_var, input_tree, target_var) in enumerate(zip(input_batches, input_trees, target_batches)):\n",
    "        \n",
    "        # Run the train function\n",
    "        loss = train(input_var, target_var, input_tree,\\\n",
    "                 encoder, decoder, tree, criterion, batch_ix, train=True)\n",
    "        #loss = train_luong(input_var, target_var, input_var.size(1), True)\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Keep track of loss\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if batch_ix == 0: continue            \n",
    "\n",
    "        if batch_ix % (print_every * batch_size) == 0:\n",
    "            print_loss_avg = print_loss_total / (print_every * batch_size)\n",
    "            print_loss_total = 0\n",
    "            print_summary = '%s (%d %d%%) %.4f' % (time_since(start, batch_ix / len(input_batches)), epoch, batch_ix / len(input_batches) * 100, print_loss_avg)\n",
    "            train_losses.append(loss)\n",
    "            print(print_summary)\n",
    "    \n",
    "    tree.eval()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_batches, input_trees, target_batches = generate_batches(input_lang, output_lang, 1, pairs_test, arr_dep=trees_test, USE_CUDA=USE_CUDA)\n",
    "        print_loss_total = 0\n",
    "        for batch_ix, (input_var, input_tree, target_var) in enumerate(zip(input_batches, input_trees, target_batches)):\n",
    "\n",
    "            # Run the train function\n",
    "            loss = train(input_var, target_var, input_tree,\\\n",
    "                     encoder, decoder, tree, criterion, batch_ix, train=False)\n",
    "\n",
    "            print_loss_total += loss\n",
    "            del loss\n",
    "            torch.cuda.empty_cache()\n",
    "    val_loss = print_loss_total / len(input_batches)\n",
    "    validation_losses.append(val_loss)\n",
    "    # Evaluating Bleu\n",
    "    #evaluator = Evaluator(encoder, decoder, input_lang, output_lang, MAX_LENGTH, True)\n",
    "    #candidates, references = evaluator.get_candidates_and_references(pairs_test, k_beams=1)\n",
    "    #bleu = BLEU(candidates, [references])\n",
    "    #if bleu[0] > best_bleu:\n",
    "    #    best_bleu = bleu[0]\n",
    "    #    torch.save(encoder.state_dict(), f'{DIR_RESULTS}/encoder.pkl')\n",
    "    #    torch.save(decoder.state_dict(), f'{DIR_RESULTS}/decoder.pkl')\n",
    "    #validation_bleu.append(bleu)\n",
    "    print(f'val_loss: {val_loss:.4f} - bleu: {0}')\n",
    "\n",
    "    # Prevent overflow gpu memory\n",
    "   # del evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(encoder, decoder, input_lang, output_lang, \n",
    "                      MAX_LENGTH, USE_CUDA)\n",
    "candidates, references = evaluator.get_candidates_and_references(pairs_test[:10000], k_beams=2)\n",
    "len(candidates), len(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'candidates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f96153bbd4cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBLEU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'candidates' is not defined"
     ]
    }
   ],
   "source": [
    "BLEU(candidates, [references]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
