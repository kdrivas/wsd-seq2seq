{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import generate_batches\n",
    "from data import prepare_data\n",
    "from data import data_to_index\n",
    "from data import DEP_LABELS\n",
    "from data import random_batch\n",
    "\n",
    "from model.encoder import Encoder\n",
    "from model.decoder import Decoder_luong\n",
    "#from model.tree_lstm import Tree_lstm\n",
    "\n",
    "from BLEU import BLEU\n",
    "\n",
    "from utils import time_since\n",
    "\n",
    "from evaluator import Evaluator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "#from validation import Evaluator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Child sum tree lstm\n",
    "class Tree_lstm(nn.Module):\n",
    "    def __init__(self, in_dim, mem_dim):\n",
    "        super(Tree_lstm, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.mem_dim = mem_dim\n",
    "        self.ioux = nn.Linear(self.in_dim, 3 * self.mem_dim)\n",
    "        self.iouh = nn.Linear(self.mem_dim, 3 * self.mem_dim)\n",
    "        self.fx = nn.Linear(self.in_dim, self.mem_dim)\n",
    "        self.fh = nn.Linear(self.mem_dim, self.mem_dim)\n",
    "\n",
    "    def node_forward(self, inputs, child_c, child_h):\n",
    "        child_h_sum = torch.sum(child_h, dim=0, keepdim=True)\n",
    "\n",
    "        iou = self.ioux(inputs) + self.iouh(child_h_sum)\n",
    "        i, o, u = torch.split(iou, iou.size(1) // 3, dim=1)\n",
    "        i, o, u = F.sigmoid(i), F.sigmoid(o), F.tanh(u)\n",
    "\n",
    "        f = F.sigmoid(\n",
    "            self.fh(child_h) +\n",
    "            self.fx(inputs).repeat(len(child_h), 1)\n",
    "        )\n",
    "        fc = torch.mul(f, child_c)\n",
    "\n",
    "        c = torch.mul(i, u) + torch.sum(fc, dim=0, keepdim=True)\n",
    "        h = torch.mul(o, F.tanh(c))\n",
    "        return c, h\n",
    "\n",
    "    def forward(self, tree, inputs):\n",
    "        tree_acum = None\n",
    "        for idx in range(tree.num_children):\n",
    "            tree_acum = self.forward(tree.children[idx], inputs)\n",
    "        \n",
    "        if tree.num_children == 0:\n",
    "            child_c = inputs[0].detach().new(1, self.mem_dim).fill_(0.).requires_grad_()\n",
    "            child_h = inputs[0].detach().new(1, self.mem_dim).fill_(0.).requires_grad_()\n",
    "        else:\n",
    "            child_c, child_h = zip(* map(lambda x: x.state, tree.children))\n",
    "            child_c, child_h = torch.cat(child_c, dim=0), torch.cat(child_h, dim=0)\n",
    "        \n",
    "        tree.state = self.node_forward(inputs[tree.idx - 1], child_c, child_h)\n",
    "        if tree_acum:\n",
    "            s, h = torch.cat((tree_acum[0], tree.state[0])), tree.state[1]\n",
    "        else:\n",
    "            s, h = tree.state\n",
    "        return s, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "MAX_LENGTH = 100\n",
    "DIR_FILES = 'data/translation/train/'\n",
    "DIR_RESULTS = 'results/step_1'\n",
    "SPLIT_TRAIN = 0.7\n",
    "SPLIT_VALID = 0.15\n",
    "SEED = 12\n",
    "# The rest is for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 115244 sentence pairs\n",
      "Filtered to 83374 pairs\n",
      "Creating vocab...\n",
      "Creating trees...\n",
      "Indexed 12248 words in input language, 22537 words in output\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, trees, _, pairs = prepare_data('eng', 'esp', dir=DIR_FILES, return_trees=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_train = np.array(pairs[:60000])\n",
    "pairs_test = np.array(pairs[60000:])\n",
    "\n",
    "trees_train = np.array(trees[:60000])\n",
    "trees_test = np.array(trees[60000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_batches, target_batches, input_tree,\\\n",
    "          encoder, decoder, tree, criterion, batch_ix, train=True):\n",
    "    \n",
    "    if train and (batch_ix % batch_size) == 0:\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        tree_optimizer.zero_grad()\n",
    "        \n",
    "    loss = 0\n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden(1)\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, encoder_hidden)\n",
    "\n",
    "    state, tree_hidden = tree(input_tree[0], encoder_outputs)\n",
    "    #encoder_outputs = torch.cat((encoder_outputs, state.unsqueeze(1)))\n",
    "    #print(encoder_outputs.shape, state.shape)\n",
    "\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))   \n",
    "    decoder_hidden = torch.cat((encoder_hidden, tree_hidden.unsqueeze(1)))\n",
    "    #decoder_hidden = encoder_hidden\n",
    "    # set the start of the sentences of the batch\n",
    "    decoder_input = torch.LongTensor([input_lang.vocab.stoi['<sos>']] * 1)\n",
    "\n",
    "    # store the decoder outputs to estimate the loss\n",
    "    all_decoder_outputs = Variable(torch.zeros(target_batches.size()[0], 1, len(output_lang.vocab.stoi)))\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "        decoder_context = decoder_context.cuda()  \n",
    "    \n",
    "    if train:\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    else:\n",
    "        use_teacher_forcing = False\n",
    "    \n",
    "    if use_teacher_forcing:        \n",
    "        # Use targets as inputs\n",
    "        for di in range(target_batches.shape[0]):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input.unsqueeze(0), decoder_context, decoder_hidden, state.unsqueeze(1))\n",
    "            \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            decoder_input = target_batches[di]\n",
    "    else:        \n",
    "        # Use decoder output as inputs\n",
    "        for di in range(target_batches.shape[0]): \n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input.unsqueeze(0), decoder_context, decoder_hidden, encoder_outputs) \n",
    "            \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            \n",
    "            # Greedy approach, take the word with highest probability\n",
    "            topv, topi = decoder_output.data.topk(1)            \n",
    "            decoder_input = Variable(torch.LongTensor(topi.cpu()).squeeze(dim=0))\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    loss = nn.NLLLoss()(all_decoder_outputs.view(-1, decoder.output_size), target_batches.contiguous().view(-1))          \n",
    "    \n",
    "    if train and (batch_ix % batch_size) == 0:\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(tree.parameters(), clip)\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        tree_optimizer.step()\n",
    "    elif train:\n",
    "        loss.backward()\n",
    "    else:\n",
    "        del all_decoder_outputs\n",
    "        del encoder_outputs\n",
    "        del decoder_hidden\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return loss.data[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 512\n",
    "emb_size = 300\n",
    "n_layers = 2\n",
    "dropout_p = 0.1\n",
    "seed = 12\n",
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len(input_lang.vocab.stoi), hidden_size, emb_size, n_layers, dropout_p, input_lang, USE_CUDA)\n",
    "decoder = Decoder_luong(attn_model, hidden_size, len(output_lang.vocab.stoi), emb_size, 2 * n_layers + 1, dropout_p, output_lang, USE_CUDA)\n",
    "tree = Tree_lstm(hidden_size, hidden_size)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    tree = tree.cuda()\n",
    "    \n",
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, encoder.parameters()), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, decoder.parameters()), lr=learning_rate)\n",
    "tree_optimizer = optim.Adam(tree.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "validation_bleu = []\n",
    "\n",
    "plot_every = 5\n",
    "print_every = 5\n",
    "validate_loss_every = 25\n",
    "best_bleu = 0\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krivas/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:75: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 10s (- 108m 31s) (1 1%) 9.2668\n",
      "2m 9s (- 98m 44s) (1 2%) 8.5496\n",
      "3m 7s (- 94m 21s) (1 3%) 7.7006\n",
      "4m 5s (- 91m 48s) (1 4%) 7.4920\n",
      "5m 2s (- 89m 37s) (1 5%) 7.2081\n",
      "5m 58s (- 87m 21s) (1 6%) 6.9733\n",
      "6m 56s (- 86m 3s) (1 7%) 6.9306\n",
      "7m 54s (- 84m 41s) (1 8%) 6.9142\n",
      "8m 53s (- 83m 41s) (1 9%) 6.8339\n",
      "9m 50s (- 82m 25s) (1 10%) 6.8981\n",
      "10m 48s (- 81m 15s) (1 11%) 6.7765\n",
      "11m 44s (- 80m 2s) (1 12%) 6.6715\n",
      "12m 44s (- 79m 7s) (1 13%) 6.7975\n",
      "13m 43s (- 78m 11s) (1 14%) 6.6339\n",
      "14m 43s (- 77m 16s) (1 16%) 6.5732\n",
      "15m 42s (- 76m 17s) (1 17%) 6.3988\n",
      "16m 41s (- 75m 21s) (1 18%) 6.4290\n",
      "17m 39s (- 74m 18s) (1 19%) 6.4801\n",
      "18m 36s (- 73m 13s) (1 20%) 6.4630\n",
      "19m 36s (- 72m 17s) (1 21%) 6.7799\n",
      "20m 38s (- 71m 29s) (1 22%) 6.8829\n",
      "21m 36s (- 70m 26s) (1 23%) 6.3316\n",
      "22m 34s (- 69m 26s) (1 24%) 6.3903\n",
      "23m 35s (- 68m 32s) (1 25%) 6.4865\n",
      "24m 34s (- 67m 35s) (1 26%) 6.4363\n",
      "25m 33s (- 66m 35s) (1 27%) 6.4828\n",
      "26m 32s (- 65m 36s) (1 28%) 6.6457\n",
      "27m 33s (- 64m 41s) (1 29%) 6.9014\n",
      "28m 33s (- 63m 44s) (1 30%) 6.7278\n",
      "29m 34s (- 62m 50s) (1 32%) 7.2372\n",
      "30m 38s (- 62m 1s) (1 33%) 6.9460\n",
      "31m 41s (- 61m 8s) (1 34%) 6.6486\n",
      "32m 43s (- 60m 14s) (1 35%) 6.3647\n",
      "33m 49s (- 59m 26s) (1 36%) 6.7855\n",
      "34m 53s (- 58m 33s) (1 37%) 6.3958\n",
      "35m 53s (- 57m 35s) (1 38%) 6.2510\n",
      "36m 56s (- 56m 39s) (1 39%) 6.2654\n",
      "38m 2s (- 55m 48s) (1 40%) 6.1790\n",
      "39m 7s (- 54m 54s) (1 41%) 6.1096\n",
      "40m 10s (- 53m 58s) (1 42%) 6.0891\n",
      "41m 13s (- 53m 2s) (1 43%) 6.2700\n",
      "42m 14s (- 52m 3s) (1 44%) 6.2576\n",
      "43m 19s (- 51m 8s) (1 45%) 6.3083\n",
      "44m 26s (- 50m 14s) (1 46%) 6.3187\n",
      "45m 27s (- 49m 15s) (1 48%) 6.4036\n",
      "46m 33s (- 48m 19s) (1 49%) 6.4806\n",
      "47m 38s (- 47m 22s) (1 50%) 6.2519\n",
      "48m 42s (- 46m 25s) (1 51%) 6.1916\n",
      "49m 42s (- 45m 23s) (1 52%) 6.1976\n",
      "50m 44s (- 44m 24s) (1 53%) 6.1827\n",
      "51m 50s (- 43m 27s) (1 54%) 6.1446\n",
      "52m 54s (- 42m 29s) (1 55%) 6.2194\n",
      "53m 58s (- 41m 30s) (1 56%) 6.2542\n",
      "55m 1s (- 40m 29s) (1 57%) 6.2972\n",
      "56m 3s (- 39m 29s) (1 58%) 6.1132\n",
      "57m 12s (- 38m 34s) (1 59%) 6.1490\n",
      "58m 18s (- 37m 35s) (1 60%) 6.2019\n",
      "59m 22s (- 36m 35s) (1 61%) 6.3534\n",
      "60m 26s (- 35m 36s) (1 62%) 6.6495\n",
      "61m 32s (- 34m 37s) (1 64%) 6.3809\n",
      "62m 37s (- 33m 37s) (1 65%) 6.1632\n",
      "63m 47s (- 32m 39s) (1 66%) 6.2189\n",
      "65m 13s (- 31m 49s) (1 67%) 6.2429\n",
      "66m 34s (- 30m 56s) (1 68%) 6.1137\n",
      "67m 57s (- 30m 3s) (1 69%) 5.9144\n",
      "69m 20s (- 29m 9s) (1 70%) 6.0120\n",
      "70m 44s (- 28m 14s) (1 71%) 5.9834\n",
      "72m 11s (- 27m 20s) (1 72%) 5.9729\n",
      "73m 36s (- 26m 24s) (1 73%) 6.0625\n",
      "75m 2s (- 25m 27s) (1 74%) 5.9957\n",
      "76m 31s (- 24m 31s) (1 75%) 6.0627\n",
      "77m 55s (- 23m 32s) (1 76%) 6.0331\n",
      "79m 26s (- 22m 34s) (1 77%) 6.6447\n",
      "80m 55s (- 21m 35s) (1 78%) 6.1470\n",
      "82m 23s (- 20m 35s) (1 80%) 6.1087\n",
      "83m 53s (- 19m 35s) (1 81%) 6.2008\n",
      "85m 21s (- 18m 34s) (1 82%) 6.1217\n",
      "86m 51s (- 17m 32s) (1 83%) 6.1686\n",
      "88m 17s (- 16m 29s) (1 84%) 6.2047\n",
      "89m 43s (- 15m 25s) (1 85%) 6.1246\n",
      "91m 11s (- 14m 21s) (1 86%) 6.0688\n",
      "92m 38s (- 13m 16s) (1 87%) 6.1736\n",
      "94m 9s (- 12m 11s) (1 88%) 6.1494\n",
      "95m 37s (- 11m 5s) (1 89%) 6.1135\n",
      "97m 6s (- 9m 59s) (1 90%) 6.1347\n",
      "98m 38s (- 8m 53s) (1 91%) 6.0736\n",
      "100m 2s (- 7m 45s) (1 92%) 5.9571\n",
      "101m 35s (- 6m 38s) (1 93%) 6.1252\n",
      "103m 6s (- 5m 30s) (1 94%) 5.9308\n",
      "104m 37s (- 4m 21s) (1 96%) 5.9644\n",
      "106m 9s (- 3m 12s) (1 97%) 6.0416\n",
      "107m 37s (- 2m 2s) (1 98%) 6.0042\n",
      "109m 7s (- 0m 52s) (1 99%) 5.9275\n",
      "val_loss: 7.2171 - bleu: 0\n",
      "144m 57s (- 13444m 53s) (2 1%) 5.9609\n",
      "146m 27s (- 6719m 3s) (2 2%) 5.9864\n",
      "147m 57s (- 4475m 35s) (2 3%) 5.9496\n",
      "149m 24s (- 3352m 10s) (2 4%) 6.3493\n",
      "150m 55s (- 2678m 46s) (2 5%) 6.1906\n",
      "152m 26s (- 2229m 22s) (2 6%) 5.9190\n",
      "153m 55s (- 1907m 34s) (2 7%) 5.9324\n",
      "155m 19s (- 1664m 57s) (2 8%) 6.1176\n",
      "156m 46s (- 1476m 22s) (2 9%) 5.9572\n",
      "158m 15s (- 1325m 24s) (2 10%) 5.8748\n",
      "159m 45s (- 1201m 45s) (2 11%) 5.9370\n",
      "161m 13s (- 1098m 21s) (2 12%) 5.8732\n",
      "162m 42s (- 1010m 37s) (2 13%) 5.8877\n",
      "164m 12s (- 935m 23s) (2 14%) 5.8018\n",
      "165m 40s (- 869m 48s) (2 16%) 5.8538\n",
      "167m 10s (- 812m 22s) (2 17%) 5.8120\n",
      "168m 43s (- 761m 46s) (2 18%) 5.9630\n",
      "170m 12s (- 716m 17s) (2 19%) 6.0220\n",
      "171m 46s (- 675m 47s) (2 20%) 6.0651\n",
      "173m 20s (- 639m 11s) (2 21%) 5.9556\n",
      "174m 49s (- 605m 38s) (2 22%) 6.2304\n",
      "176m 17s (- 574m 56s) (2 23%) 6.0683\n",
      "177m 49s (- 546m 59s) (2 24%) 6.2106\n",
      "179m 18s (- 521m 6s) (2 25%) 6.0740\n",
      "180m 47s (- 497m 10s) (2 26%) 5.9883\n",
      "182m 14s (- 474m 53s) (2 27%) 5.8433\n",
      "183m 45s (- 454m 17s) (2 28%) 5.8558\n",
      "185m 19s (- 435m 10s) (2 29%) 5.8518\n",
      "186m 52s (- 417m 14s) (2 30%) 5.7551\n",
      "188m 26s (- 400m 25s) (2 32%) 5.9118\n",
      "189m 56s (- 384m 28s) (2 33%) 6.0466\n",
      "191m 27s (- 369m 27s) (2 34%) 6.0488\n",
      "192m 59s (- 355m 17s) (2 35%) 5.9540\n",
      "194m 33s (- 341m 53s) (2 36%) 6.0313\n",
      "196m 3s (- 329m 5s) (2 37%) 6.1084\n",
      "197m 40s (- 317m 6s) (2 38%) 5.9432\n",
      "199m 13s (- 305m 33s) (2 39%) 6.0781\n",
      "200m 29s (- 294m 7s) (2 40%) 5.9945\n",
      "201m 48s (- 283m 18s) (2 41%) 6.0364\n",
      "203m 7s (- 272m 56s) (2 42%) 5.8965\n",
      "204m 25s (- 263m 1s) (2 43%) 5.9393\n",
      "205m 43s (- 253m 29s) (2 44%) 6.0157\n",
      "207m 2s (- 244m 20s) (2 45%) 6.0123\n",
      "208m 19s (- 235m 33s) (2 46%) 6.0986\n",
      "209m 40s (- 227m 8s) (2 48%) 5.9054\n",
      "211m 0s (- 219m 2s) (2 49%) 6.1176\n",
      "212m 17s (- 211m 10s) (2 50%) 5.9993\n",
      "213m 37s (- 203m 37s) (2 51%) 6.1928\n",
      "214m 57s (- 196m 18s) (2 52%) 6.1525\n",
      "216m 15s (- 189m 13s) (2 53%) 6.1011\n",
      "217m 37s (- 182m 25s) (2 54%) 5.8632\n",
      "219m 1s (- 175m 50s) (2 55%) 6.0109\n",
      "220m 20s (- 169m 24s) (2 56%) 5.9341\n",
      "221m 40s (- 163m 10s) (2 57%) 5.8055\n",
      "223m 5s (- 157m 10s) (2 58%) 5.8375\n",
      "224m 29s (- 151m 19s) (2 59%) 5.8417\n",
      "225m 52s (- 145m 37s) (2 60%) 5.7693\n",
      "227m 10s (- 140m 1s) (2 61%) 5.7121\n",
      "228m 29s (- 134m 34s) (2 62%) 5.6953\n",
      "229m 49s (- 129m 16s) (2 64%) 5.6266\n",
      "231m 18s (- 124m 10s) (2 65%) 5.6694\n",
      "232m 50s (- 119m 14s) (2 66%) 5.6760\n",
      "234m 21s (- 114m 23s) (2 67%) 5.6947\n",
      "235m 54s (- 109m 39s) (2 68%) 5.6871\n",
      "237m 27s (- 105m 1s) (2 69%) 5.7324\n",
      "239m 3s (- 100m 30s) (2 70%) 5.8009\n",
      "240m 40s (- 96m 5s) (2 71%) 5.8612\n",
      "242m 19s (- 91m 45s) (2 72%) 5.7613\n",
      "243m 55s (- 87m 29s) (2 73%) 5.7309\n",
      "245m 34s (- 83m 19s) (2 74%) 5.7581\n",
      "247m 7s (- 79m 10s) (2 75%) 5.7594\n",
      "248m 41s (- 75m 7s) (2 76%) 5.8632\n",
      "250m 19s (- 71m 9s) (2 77%) 5.7141\n",
      "251m 57s (- 67m 14s) (2 78%) 5.7328\n",
      "253m 41s (- 63m 25s) (2 80%) 5.6934\n",
      "255m 18s (- 59m 37s) (2 81%) 5.7484\n",
      "256m 57s (- 55m 53s) (2 82%) 5.7032\n",
      "258m 36s (- 52m 13s) (2 83%) 5.8068\n",
      "260m 15s (- 48m 35s) (2 84%) 5.8523\n",
      "261m 54s (- 45m 0s) (2 85%) 5.7551\n",
      "263m 37s (- 41m 29s) (2 86%) 5.7629\n",
      "265m 16s (- 38m 0s) (2 87%) 5.7147\n",
      "266m 57s (- 34m 34s) (2 88%) 5.7965\n",
      "268m 38s (- 31m 10s) (2 89%) 5.7006\n",
      "270m 11s (- 27m 48s) (2 90%) 5.9663\n",
      "271m 42s (- 24m 29s) (2 91%) 5.7816\n",
      "273m 13s (- 21m 11s) (2 92%) 5.6976\n",
      "274m 49s (- 17m 57s) (2 93%) 5.7496\n",
      "276m 27s (- 14m 45s) (2 94%) 5.6986\n",
      "278m 7s (- 11m 35s) (2 96%) 5.7755\n",
      "279m 45s (- 8m 27s) (2 97%) 5.8449\n",
      "281m 24s (- 5m 21s) (2 98%) 5.8384\n",
      "283m 4s (- 2m 16s) (2 99%) 5.7804\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs): \n",
    "    # Shuffle data\n",
    "    #id_aux = np.random.permutation(np.arange(len(pairs_train)))\n",
    "    #pairs_train = pairs_train[id_aux]\n",
    "    \n",
    "    tree.train()\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    # Get the batches for this epoch\n",
    "    input_batches, input_trees, target_batches = generate_batches(input_lang, output_lang, 1, pairs_train, arr_dep=trees_train, USE_CUDA=USE_CUDA)    \n",
    "    print_loss_total = 0\n",
    "    for batch_ix, (input_var, input_tree, target_var) in enumerate(zip(input_batches, input_trees, target_batches)):\n",
    "        \n",
    "        # Run the train function\n",
    "        loss = train(input_var, target_var, input_tree,\\\n",
    "                 encoder, decoder, tree, criterion, batch_ix, train=True)\n",
    "        #loss = train_luong(input_var, target_var, input_var.size(1), True)\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Keep track of loss\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if batch_ix == 0: continue            \n",
    "\n",
    "        if batch_ix % (print_every * batch_size) == 0:\n",
    "            print_loss_avg = print_loss_total / (print_every * batch_size)\n",
    "            print_loss_total = 0\n",
    "            print_summary = '%s (%d %d%%) %.4f' % (time_since(start, batch_ix / len(input_batches)), epoch, batch_ix / len(input_batches) * 100, print_loss_avg)\n",
    "            train_losses.append(loss)\n",
    "            print(print_summary)\n",
    "    \n",
    "    tree.eval()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_batches, input_trees, target_batches = generate_batches(input_lang, output_lang, 1, pairs_test, arr_dep=trees_test, USE_CUDA=USE_CUDA)\n",
    "        print_loss_total = 0\n",
    "        for batch_ix, (input_var, input_tree, target_var) in enumerate(zip(input_batches, input_trees, target_batches)):\n",
    "\n",
    "            # Run the train function\n",
    "            loss = train(input_var, target_var, input_tree,\\\n",
    "                     encoder, decoder, tree, criterion, batch_ix, train=False)\n",
    "\n",
    "            print_loss_total += loss\n",
    "            del loss\n",
    "            torch.cuda.empty_cache()\n",
    "    val_loss = print_loss_total / len(input_batches)\n",
    "    validation_losses.append(val_loss)\n",
    "    # Evaluating Bleu\n",
    "    #evaluator = Evaluator(encoder, decoder, input_lang, output_lang, MAX_LENGTH, True)\n",
    "    #candidates, references = evaluator.get_candidates_and_references(pairs_test, k_beams=1)\n",
    "    #bleu = BLEU(candidates, [references])\n",
    "    #if bleu[0] > best_bleu:\n",
    "    #    best_bleu = bleu[0]\n",
    "    #    torch.save(encoder.state_dict(), f'{DIR_RESULTS}/encoder.pkl')\n",
    "    #    torch.save(decoder.state_dict(), f'{DIR_RESULTS}/decoder.pkl')\n",
    "    #validation_bleu.append(bleu)\n",
    "    print(f'val_loss: {val_loss:.4f} - bleu: {0}')\n",
    "\n",
    "    # Prevent overflow gpu memory\n",
    "   # del evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(encoder, decoder, input_lang, output_lang, \n",
    "                      MAX_LENGTH, USE_CUDA)\n",
    "candidates, references = evaluator.get_candidates_and_references(pairs_test[:10000], k_beams=2)\n",
    "len(candidates), len(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4428"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krivas/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/krivas/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for dimension 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-711bfa91ebfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tree\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-b33ecf87143f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_batches, target_batches, input_tree, encoder, decoder, tree, criterion, batch_ix, train)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m#encoder_outputs = torch.cat((encoder_outputs, state.unsqueeze(1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print(encoder_outputs.shape, state.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6432ce73daf6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tree, inputs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtree_acum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_children\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mtree_acum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_children\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6432ce73daf6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tree, inputs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtree_acum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_children\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mtree_acum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_children\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6432ce73daf6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tree, inputs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mchild_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtree_acum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_acum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for dimension 0 with size 5"
     ]
    }
   ],
   "source": [
    "loss = train(input_var, target_var, input_tree,\\\n",
    "                 encoder, decoder, tree, criterion, batch_ix, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4428"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 'sometimes you gotta do what you gotta do .', 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ' '.join([input_lang.vocab.itos[t] for t in input_var[:-1]])\n",
    "len(sentence.split()), sentence, len(input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp = StanfordCoreNLP(r'data/lib/stanford-corenlp')\n",
    "temp_tree = nlp.dependency_parse(\"hi everyone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ROOT', 0, 2), ('dep', 2, 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"', '\"', '\"', '\"', '\"']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[?|.|!|\"]', 'asdasdasdasdas\"\"\"\"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = 'asdas\"\"\"\"\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"asdas'''''\""
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd.replace('\"', \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ROOT', 0, 11),\n",
       " ('det', 2, 1),\n",
       " ('nsubj', 11, 2),\n",
       " ('punct', 8, 3),\n",
       " ('amod', 8, 4),\n",
       " ('punct', 8, 5),\n",
       " ('cc', 8, 6),\n",
       " ('punct', 8, 7),\n",
       " ('dep', 2, 8),\n",
       " ('punct', 8, 9),\n",
       " ('cop', 11, 10),\n",
       " ('punct', 11, 12)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arbol: 0 N hijos: 1\n",
      "parent: 0 child 11\n",
      "\n",
      "arbol: 11 N hijos: 3\n",
      "parent: 11 child 2\n",
      "\n",
      "arbol: 2 N hijos: 2\n",
      "parent: 2 child 1\n",
      "\n",
      "arbol: 2 N hijos: 2\n",
      "parent: 2 child 8\n",
      "\n",
      "arbol: 8 N hijos: 6\n",
      "parent: 8 child 3\n",
      "\n",
      "arbol: 8 N hijos: 6\n",
      "parent: 8 child 4\n",
      "\n",
      "arbol: 8 N hijos: 6\n",
      "parent: 8 child 5\n",
      "\n",
      "arbol: 8 N hijos: 6\n",
      "parent: 8 child 6\n",
      "\n",
      "arbol: 8 N hijos: 6\n",
      "parent: 8 child 7\n",
      "\n",
      "arbol: 8 N hijos: 6\n",
      "parent: 8 child 9\n",
      "\n",
      "arbol: 11 N hijos: 3\n",
      "parent: 11 child 10\n",
      "\n",
      "arbol: 11 N hijos: 3\n",
      "parent: 11 child 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import print_tree\n",
    "print_tree(input_tree[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs_test[4428][0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krivas/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/krivas/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-60f746a749e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#[input_var, _, _, _, _, _, _, _] = input_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Run the train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tree\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7422cd858065>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_batches, target_batches, input_tree, encoder, decoder, tree, criterion, batch_ix, train)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n\u001b[0;32m---> 48\u001b[0;31m                 decoder_input.unsqueeze(0), decoder_context, decoder_hidden, encoder_outputs) \n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mall_decoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/neural-wsd/new_experiments/model/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word_input, last_context, last_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# rnn_input: (seq_len=1, batch_size, embedding_size + encoder_hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# last_hidden: (num_layers, batch_size, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m# rnn_output: (seq_len=1, batch_size, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# hidden: same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mhas_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_ptrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_flat_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mfirst_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mfirst_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_buf_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_buf_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \"\"\"\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_parameters\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmemo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch_ix, (input_var, input_tree, target_var) in enumerate(zip(input_batches, input_trees, target_batches)):\n",
    "    \n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "    \n",
    "        #[input_var, _, _, _, _, _, _, _] = input_batch\n",
    "        # Run the train function\n",
    "        loss = train(input_var, target_var, input_tree,\\\n",
    "                 encoder, decoder, tree, criterion, batch_ix, train=False)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        del loss\n",
    "        torch.cuda.empty_cache()\n",
    "val_loss = print_loss_total / len(input_batches)\n",
    "validation_losses.append(val_loss)\n",
    "\n",
    "print(f'val_loss: {val_loss:.4f} - bleu: {0}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'candidates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f96153bbd4cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBLEU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'candidates' is not defined"
     ]
    }
   ],
   "source": [
    "BLEU(candidates, [references]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.000017166137695,\n",
       " 7.632211208343506,\n",
       " 5.206856727600098,\n",
       " 4.905932903289795,\n",
       " 7.33738899230957,\n",
       " 7.596729278564453,\n",
       " 5.707835674285889,\n",
       " 6.398375511169434,\n",
       " 7.879125595092773,\n",
       " 3.5190353393554688,\n",
       " 5.947818279266357,\n",
       " 6.372866630554199]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
