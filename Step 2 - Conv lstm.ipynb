{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import generate_batches\n",
    "from data import prepare_data\n",
    "from data import data_to_index\n",
    "from data import DEP_LABELS\n",
    "from data import random_batch\n",
    "\n",
    "from model.encoder import Encoder\n",
    "from model.decoder import Decoder_luong\n",
    "from model.gcn import Gcn\n",
    "\n",
    "from BLEU import BLEU\n",
    "\n",
    "from utils import time_since\n",
    "\n",
    "from evaluator import Evaluator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "#from validation import Evaluator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "MAX_LENGTH = 100\n",
    "DIR_FILES = 'data/translation/train/'\n",
    "DIR_RESULTS = 'results/step_1'\n",
    "SPLIT_TRAIN = 0.7\n",
    "SPLIT_VALID = 0.15\n",
    "# The rest is for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 115244 sentence pairs\n",
      "Filtered to 84144 pairs\n",
      "Creating vocab...\n",
      "Creating matrixes...\n",
      "Indexed 12330 words in input language, 21913 words in output\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, input_trees, _, pairs = prepare_data('eng', 'esp', dir=DIR_FILES, return_trees=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrixes = input_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_train = np.array(pairs[:60000])\n",
    "pairs_test = np.array(pairs[60000:])\n",
    "\n",
    "matrixes_train = np.array(input_matrixes[:60000])\n",
    "matrixes_test = np.array(input_matrixes[60000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_batches, target_batches, input_matrixes,\\\n",
    "          encoder, decoder, gcn, criterion, batch_ix, train=True):\n",
    "    \n",
    "    if train and (batch_ix % batch_size) == 0:\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        gcn_optimizer.zero_grad()\n",
    "        \n",
    "    loss = 0\n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden(1)\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, encoder_hidden)\n",
    "\n",
    "    encoder_outputs = nn.LeakyReLU()(gcn(encoder_outputs.squeeze(1), input_matrixes).unsqueeze(1))\n",
    "    decoder_hidden = encoder_hidden\n",
    "    #print(encoder_outputs.shape, state.shape)\n",
    "    \n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))   \n",
    "    #decoder_hidden = encoder_hidden\n",
    "    # set the start of the sentences of the batch\n",
    "    decoder_input = torch.LongTensor([input_lang.vocab.stoi['<sos>']] * 1)\n",
    "\n",
    "    # store the decoder outputs to estimate the loss\n",
    "    all_decoder_outputs = Variable(torch.zeros(target_batches.size()[0], 1, len(output_lang.vocab.stoi)))\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "        decoder_context = decoder_context.cuda()  \n",
    "    \n",
    "    if train:\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    else:\n",
    "        use_teacher_forcing = False\n",
    "    \n",
    "    if use_teacher_forcing:        \n",
    "        # Use targets as inputs\n",
    "        for di in range(target_batches.shape[0]):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input.unsqueeze(0), decoder_context, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            decoder_input = target_batches[di]\n",
    "    else:        \n",
    "        # Use decoder output as inputs\n",
    "        for di in range(target_batches.shape[0]): \n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input.unsqueeze(0), decoder_context, decoder_hidden, encoder_outputs) \n",
    "            \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            \n",
    "            # Greedy approach, take the word with highest probability\n",
    "            topv, topi = decoder_output.data.topk(1)            \n",
    "            decoder_input = Variable(torch.LongTensor(topi.cpu()).squeeze(dim=0))\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    loss = nn.NLLLoss()(all_decoder_outputs.view(-1, decoder.output_size), target_batches.contiguous().view(-1))          \n",
    "    \n",
    "    if train and (batch_ix % batch_size) == 0:\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(gcn.parameters(), clip)\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        gcn_optimizer.step()\n",
    "    elif train:\n",
    "        loss.backward()\n",
    "    \n",
    "    return loss.item() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 512\n",
    "emb_size = 300\n",
    "n_layers = 2\n",
    "dropout_p = 0.1\n",
    "seed = 12\n",
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "class Gcn(Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(Gcn, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.init_params()\n",
    "        \n",
    "    def init_params(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "            \n",
    "    def forward(self, input, adj):\n",
    "        # input: (seq_len x in_features)\n",
    "        # adj: (seq_len x seq_len)\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len(input_lang.vocab.stoi), hidden_size, emb_size, n_layers, dropout_p, input_lang, USE_CUDA)\n",
    "decoder = Decoder_luong(attn_model, hidden_size, len(output_lang.vocab.stoi), emb_size, 2 * n_layers, dropout_p, output_lang, USE_CUDA)\n",
    "gcn = Gcn(hidden_size, hidden_size)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    gcn = gcn.cuda()\n",
    "    \n",
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, encoder.parameters()), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, decoder.parameters()), lr=learning_rate)\n",
    "gcn_optimizer = optim.Adam(gcn.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "validation_bleu = []\n",
    "\n",
    "plot_every = 5\n",
    "print_every = 5\n",
    "validate_loss_every = 25\n",
    "best_bleu = 0\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729m 16s (- 13856m 15s) (1 1%) 8.9886\n",
      "729m 44s (- 13865m 2s) (1 2%) 7.8141\n",
      "730m 12s (- 13874m 0s) (1 3%) 7.6746\n",
      "730m 40s (- 13882m 54s) (1 4%) 7.2135\n",
      "731m 8s (- 13891m 46s) (1 5%) 6.9713\n",
      "731m 36s (- 13900m 41s) (1 6%) 6.8048\n",
      "732m 4s (- 13909m 34s) (1 7%) 6.9077\n",
      "732m 33s (- 13918m 32s) (1 8%) 6.5687\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs): \n",
    "    # Shuffle data\n",
    "    #id_aux = np.random.permutation(np.arange(len(pairs_train)))\n",
    "    #pairs_train = pairs_train[id_aux]\n",
    "    \n",
    "    # Get the batches for this epoch\n",
    "    input_batches, input_matrixes, target_batches = generate_batches(input_lang, output_lang, 1, pairs_train, arr_dep=matrixes_train, USE_CUDA=USE_CUDA)    \n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    gcn.train()\n",
    "        \n",
    "    for batch_ix, (input_var, input_matrix, target_var) in enumerate(zip(input_batches, input_matrixes, target_batches)):\n",
    "        \n",
    "        # Run the train function\n",
    "        input_matrix = np.array(input_matrix[0])\n",
    "        degree = np.array(np.sum(input_matrix, axis=0))\n",
    "        degree = np.matrix(np.diag(degree))\n",
    "        \n",
    "        input_matrix = torch.FloatTensor(np.linalg.inv(degree) * input_matrix)\n",
    "        if USE_CUDA:\n",
    "            input_matrix = input_matrix.cuda()\n",
    "\n",
    "        loss = train(input_var, target_var, input_matrix,\\\n",
    "                 encoder, decoder, gcn, criterion, batch_ix, train=True)\n",
    "        #loss = train_luong(input_var, target_var, input_var.size(1), True)\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Keep track of loss\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if batch_ix == 0: continue            \n",
    "\n",
    "        if batch_ix % (print_every * batch_size)  == 0:\n",
    "            print_loss_avg = print_loss_total / (print_every * batch_size)\n",
    "            print_loss_total = 0\n",
    "            print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, batch_ix / len(input_batches) * 100, print_loss_avg)\n",
    "            train_losses.append(loss)\n",
    "            print(print_summary)\n",
    "    \n",
    "    input_batches, input_matrixes, target_batches = generate_batches(input_lang, output_lang, 1, pairs_test, arr_dep=matrixes_test, USE_CUDA=USE_CUDA)\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    gcn.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        print_loss_total = 0\n",
    "        for batch_ix, (input_var, input_matrix, target_var) in enumerate(zip(input_batches, input_matrixes, target_batches)):\n",
    "    \n",
    "            # Run the train function\n",
    "            input_matrix = np.array(input_matrix[0])\n",
    "            degree = np.array(np.sum(input_matrix, axis=0))\n",
    "            degree = np.matrix(np.diag(degree))\n",
    "\n",
    "            input_matrix = torch.FloatTensor(np.linalg.inv(degree) * input_matrix)\n",
    "            if USE_CUDA:\n",
    "                input_matrix = input_matrix.cuda()\n",
    "            loss = train(input_var, target_var, input_matrix,\\\n",
    "                     encoder, decoder, gcn, criterion, batch_ix, train=False)\n",
    "\n",
    "            print_loss_total += loss\n",
    "            torch.cuda.empty_cache()\n",
    "    val_loss = print_loss_total / len(input_batches)\n",
    "    validation_losses.append(val_loss)\n",
    "    # Evaluating Bleu\n",
    "    #evaluator = Evaluator(encoder, decoder, input_lang, output_lang, MAX_LENGTH, True)\n",
    "    #candidates, references = evaluator.get_candidates_and_references(pairs_test, k_beams=1)\n",
    "    #bleu = BLEU(candidates, [references])\n",
    "    #if bleu[0] > best_bleu:\n",
    "    #    best_bleu = bleu[0]\n",
    "    #    torch.save(encoder.state_dict(), f'{DIR_RESULTS}/encoder.pkl')\n",
    "    #    torch.save(decoder.state_dict(), f'{DIR_RESULTS}/decoder.pkl')\n",
    "    #validation_bleu.append(bleu)\n",
    "    print(f'val_loss: {val_loss:.4f} - bleu: {0}')\n",
    "\n",
    "    # Prevent overflow gpu memory\n",
    "    #del evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0., 1., 0., 0., 1., 1.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 6. 2. 2. 2. 5. 2. 3. 2. 2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[2., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 6., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 2., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 2., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 5., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 3., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 2., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.array(np.sum(temp, axis=0))\n",
    "print(D)\n",
    "D = np.matrix(np.diag(D))\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.16666667, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.2       , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.5       , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.33333333, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.5       , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.5       ]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D**-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.16666667, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.2       , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.5       , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.33333333, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.5       , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.5       ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(temp, np.linalg.inv(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5       , 0.5       , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.16666667, 0.16666667, 0.16666667, 0.        , 0.        ,\n",
       "         0.16666667, 0.        , 0.        , 0.16666667, 0.16666667],\n",
       "        [0.        , 0.5       , 0.5       , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "         0.5       , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
       "         0.5       , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.2       , 0.        , 0.2       , 0.2       ,\n",
       "         0.2       , 0.        , 0.2       , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.5       , 0.5       , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.33333333, 0.33333333, 0.33333333, 0.        , 0.        ],\n",
       "        [0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.5       , 0.        ],\n",
       "        [0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.5       ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D**-1*temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 1]), (7, 7))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 0\n",
    "input_batches[ix].shape, input_matrixes[ix][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 7])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he gave me 10 ,000 yen . <eos>'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([input_lang.vocab.itos[w] for w in input_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(encoder, decoder, input_lang, output_lang, \n",
    "                      MAX_LENGTH, USE_CUDA)\n",
    "candidates, references = evaluator.get_candidates_and_references(pairs_test[:10000], k_beams=2)\n",
    "len(candidates), len(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28063523097173265,\n",
       " [0.6573135078342698,\n",
       "  0.37567686039915427,\n",
       "  0.22488307382629802,\n",
       "  0.13494545201862276],\n",
       " 0.953820572858132)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEU(candidates, [references]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.041672706604004,\n",
       " 7.149496555328369,\n",
       " 14.810012817382812,\n",
       " 12.101698875427246,\n",
       " 9.06682014465332,\n",
       " 7.260944366455078,\n",
       " 6.044005393981934,\n",
       " 6.0010833740234375,\n",
       " 7.1673264503479,\n",
       " 6.06639289855957,\n",
       " 6.229933261871338,\n",
       " 8.623738288879395,\n",
       " 5.882908344268799,\n",
       " 4.927737236022949,\n",
       " 5.671040058135986,\n",
       " 7.489520072937012,\n",
       " 5.501565456390381,\n",
       " 5.914140224456787,\n",
       " 6.912267208099365,\n",
       " 6.224165916442871,\n",
       " 7.6937079429626465,\n",
       " 6.377658843994141,\n",
       " 8.010522842407227,\n",
       " 8.193879127502441,\n",
       " 7.284544944763184,\n",
       " 4.864162445068359,\n",
       " 6.447579860687256,\n",
       " 6.805881977081299,\n",
       " 5.03970193862915,\n",
       " 6.144567012786865,\n",
       " 5.522188186645508,\n",
       " 6.3946533203125,\n",
       " 7.317024230957031,\n",
       " 7.084739685058594,\n",
       " 4.866414546966553,\n",
       " 4.8789286613464355,\n",
       " 6.360021114349365,\n",
       " 5.258521556854248,\n",
       " 7.594843864440918,\n",
       " 5.99109411239624,\n",
       " 6.1218085289001465,\n",
       " 4.6263885498046875,\n",
       " 6.505831241607666,\n",
       " 6.49678897857666,\n",
       " 6.661844253540039,\n",
       " 5.703457832336426,\n",
       " 6.080120086669922,\n",
       " 5.556210994720459,\n",
       " 4.3718485832214355,\n",
       " 7.616245269775391,\n",
       " 5.660667896270752,\n",
       " 4.477021217346191,\n",
       " 5.971453666687012,\n",
       " 7.151060581207275,\n",
       " 7.284686088562012,\n",
       " 4.710358619689941,\n",
       " 5.699878692626953,\n",
       " 5.8283185958862305,\n",
       " 5.429839134216309,\n",
       " 5.627746105194092,\n",
       " 8.024958610534668,\n",
       " 7.326678276062012,\n",
       " 6.238666534423828,\n",
       " 4.728693962097168,\n",
       " 6.361328125,\n",
       " 5.92225456237793,\n",
       " 6.291927337646484,\n",
       " 6.011835098266602,\n",
       " 7.155662536621094,\n",
       " 5.337331295013428,\n",
       " 7.359513282775879,\n",
       " 6.708942890167236,\n",
       " 6.291254997253418,\n",
       " 6.5870819091796875,\n",
       " 6.9649858474731445,\n",
       " 5.453511714935303,\n",
       " 5.605909824371338,\n",
       " 6.4293036460876465,\n",
       " 6.750390529632568,\n",
       " 8.476428031921387,\n",
       " 5.792107582092285,\n",
       " 7.52388334274292,\n",
       " 5.88793420791626,\n",
       " 5.64914083480835,\n",
       " 5.583569049835205,\n",
       " 7.05214786529541,\n",
       " 7.007693767547607,\n",
       " 6.556692600250244,\n",
       " 5.914644241333008,\n",
       " 7.384115219116211,\n",
       " 6.446426868438721,\n",
       " 5.6869215965271,\n",
       " 6.317768573760986,\n",
       " 6.537539958953857,\n",
       " 8.257403373718262,\n",
       " 6.223647594451904,\n",
       " 7.760086536407471,\n",
       " 6.339871883392334,\n",
       " 6.288576602935791,\n",
       " 6.117007732391357,\n",
       " 4.761729717254639,\n",
       " 5.098626136779785,\n",
       " 5.2466816902160645,\n",
       " 4.348966121673584,\n",
       " 6.218953609466553,\n",
       " 4.525362968444824,\n",
       " 8.28030014038086,\n",
       " 5.524833679199219,\n",
       " 7.029933452606201,\n",
       " 5.692931175231934,\n",
       " 5.107240200042725,\n",
       " 7.430395126342773,\n",
       " 6.536320686340332,\n",
       " 6.89471960067749,\n",
       " 4.141633987426758,\n",
       " 5.832042217254639,\n",
       " 5.386961460113525,\n",
       " 5.803618907928467,\n",
       " 6.419718265533447,\n",
       " 6.172667503356934,\n",
       " 7.619015216827393,\n",
       " 6.166060447692871,\n",
       " 6.7607011795043945,\n",
       " 5.820564270019531,\n",
       " 6.111392021179199,\n",
       " 4.593202114105225,\n",
       " 6.3956732749938965,\n",
       " 4.5033745765686035,\n",
       " 5.831901550292969,\n",
       " 6.683056354522705,\n",
       " 6.531650543212891,\n",
       " 4.357241630554199,\n",
       " 6.526559829711914,\n",
       " 5.965932369232178,\n",
       " 7.174294948577881,\n",
       " 5.76188325881958,\n",
       " 5.928871154785156,\n",
       " 6.473082542419434,\n",
       " 6.172927379608154,\n",
       " 6.565548896789551]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"tom wasn 't convinced it was a good idea .\",\n",
       "       'tom no estaba convencido de que fuera una buena idea .'],\n",
       "      dtype='<U245')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_test[480]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['just act as if nothing has happened .',\n",
       "       'haga de cuenta que nada ha ocurrido .'],\n",
       "      dtype='<U245')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_train[80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
