{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from data import generate_batches\n",
    "from data import prepare_data\n",
    "from data import data_to_index\n",
    "from data import DEP_LABELS\n",
    "from data import random_batch\n",
    "\n",
    "from model.encoder import Encoder\n",
    "from model.decoder import Decoder_luong\n",
    "from model.gcn import Gcn\n",
    "\n",
    "from BLEU import BLEU\n",
    "\n",
    "from utils import time_since\n",
    "\n",
    "from evaluator import Evaluator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "#from validation import Evaluator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = False\n",
    "MAX_LENGTH = 100\n",
    "DIR_FILES = 'data/translation/train/'\n",
    "DIR_RESULTS = 'results/step_1'\n",
    "SPLIT_TRAIN = 0.7\n",
    "SPLIT_VALID = 0.15\n",
    "# The rest is for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 115244 sentence pairs\n",
      "Filtered to 84144 pairs\n",
      "Creating vocab...\n",
      "Creating matrixes...\n",
      "Indexed 12330 words in input language, 21913 words in output\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, input_trees, _, pairs = prepare_data('eng', 'esp', dir=DIR_FILES, return_trees=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrixes = input_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_train = np.array(pairs[:60000])\n",
    "pairs_test = np.array(pairs[60000:])\n",
    "\n",
    "matrixes_train = np.array(input_matrixes[:60000])\n",
    "matrixes_test = np.array(input_matrixes[60000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input_batches, target_batches, input_matrixes,\\\n",
    "          encoder, decoder, gcn, criterion, batch_ix, train=True):\n",
    "    \n",
    "    if train and (batch_ix % batch_size) == 0:\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        gcn_optimizer.zero_grad()\n",
    "        \n",
    "    loss = 0\n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden(1)\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, encoder_hidden)\n",
    "\n",
    "    encoder_outputs = nn.LeakyReLU()(gcn(encoder_outputs.squeeze(1), input_matrixes).unsqueeze(1))\n",
    "    decoder_hidden = encoder_hidden\n",
    "    #print(encoder_outputs.shape, state.shape)\n",
    "    \n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))   \n",
    "    #decoder_hidden = encoder_hidden\n",
    "    # set the start of the sentences of the batch\n",
    "    decoder_input = torch.LongTensor([input_lang.vocab.stoi['<sos>']] * 1)\n",
    "\n",
    "    # store the decoder outputs to estimate the loss\n",
    "    all_decoder_outputs = Variable(torch.zeros(target_batches.size()[0], 1, len(output_lang.vocab.stoi)))\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "        decoder_context = decoder_context.cuda()  \n",
    "    \n",
    "    if train:\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    else:\n",
    "        use_teacher_forcing = False\n",
    "    \n",
    "    if use_teacher_forcing:        \n",
    "        # Use targets as inputs\n",
    "        for di in range(target_batches.shape[0]):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input.unsqueeze(0), decoder_context, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            decoder_input = target_batches[di]\n",
    "    else:        \n",
    "        # Use decoder output as inputs\n",
    "        for di in range(target_batches.shape[0]): \n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input.unsqueeze(0), decoder_context, decoder_hidden, encoder_outputs) \n",
    "            \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            \n",
    "            # Greedy approach, take the word with highest probability\n",
    "            topv, topi = decoder_output.data.topk(1)            \n",
    "            decoder_input = Variable(torch.LongTensor(topi.cpu()).squeeze(dim=0))\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    loss = nn.NLLLoss()(all_decoder_outputs.view(-1, decoder.output_size), target_batches.contiguous().view(-1))          \n",
    "    \n",
    "    if train and (batch_ix % batch_size) == 0:\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "        torch.nn.utils.clip_grad_norm_(gcn.parameters(), clip)\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        gcn_optimizer.step()\n",
    "    elif train:\n",
    "        loss.backward()\n",
    "    \n",
    "    return loss.item() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 512\n",
    "emb_size = 300\n",
    "n_layers = 2\n",
    "dropout_p = 0.1\n",
    "seed = 12\n",
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "class Gcn(Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(Gcn, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.init_params()\n",
    "        \n",
    "    def init_params(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "            \n",
    "    def forward(self, input, adj):\n",
    "        # input: (seq_len x in_features)\n",
    "        # adj: (seq_len x seq_len)\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len(input_lang.vocab.stoi), hidden_size, emb_size, n_layers, dropout_p, input_lang, USE_CUDA)\n",
    "decoder = Decoder_luong(attn_model, hidden_size, len(output_lang.vocab.stoi), emb_size, 2 * n_layers, dropout_p, output_lang, USE_CUDA)\n",
    "gcn = Gcn(hidden_size, hidden_size)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    gcn = gcn.cuda()\n",
    "    \n",
    "learning_rate = 0.001\n",
    "encoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, encoder.parameters()), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(filter(lambda p: p.requires_grad, decoder.parameters()), lr=learning_rate)\n",
    "gcn_optimizer = optim.Adam(gcn.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "validation_bleu = []\n",
    "\n",
    "plot_every = 5\n",
    "print_every = 5\n",
    "validate_loss_every = 25\n",
    "best_bleu = 0\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8m 58s (- 170m 39s) (1 1%) 8.6812\n",
      "17m 2s (- 323m 51s) (1 2%) 7.7930\n",
      "25m 8s (- 477m 42s) (1 3%) 7.1848\n",
      "33m 11s (- 630m 43s) (1 4%) 7.0467\n",
      "41m 15s (- 784m 2s) (1 5%) 6.8925\n",
      "49m 20s (- 937m 24s) (1 6%) 6.9293\n",
      "57m 24s (- 1090m 50s) (1 7%) 6.7174\n",
      "65m 28s (- 1243m 55s) (1 8%) 6.5930\n",
      "73m 33s (- 1397m 36s) (1 9%) 6.4553\n",
      "81m 35s (- 1550m 15s) (1 10%) 6.4956\n",
      "89m 41s (- 1704m 2s) (1 11%) 6.3985\n",
      "97m 45s (- 1857m 17s) (1 12%) 6.4574\n",
      "105m 48s (- 2010m 18s) (1 13%) 6.8812\n",
      "113m 49s (- 2162m 44s) (1 14%) 6.5730\n",
      "121m 51s (- 2315m 25s) (1 16%) 6.4642\n",
      "129m 59s (- 2469m 44s) (1 17%) 6.3321\n",
      "137m 58s (- 2621m 33s) (1 18%) 6.3489\n",
      "146m 5s (- 2775m 36s) (1 19%) 6.2115\n",
      "154m 12s (- 2929m 52s) (1 20%) 6.1239\n",
      "162m 15s (- 3082m 54s) (1 21%) 6.1571\n",
      "170m 21s (- 3236m 45s) (1 22%) 6.1340\n",
      "178m 23s (- 3389m 30s) (1 23%) 6.0719\n",
      "186m 25s (- 3542m 13s) (1 24%) 6.2250\n",
      "194m 29s (- 3695m 12s) (1 25%) 6.1202\n",
      "202m 35s (- 3849m 13s) (1 26%) 6.0625\n",
      "210m 36s (- 4001m 40s) (1 27%) 6.1299\n",
      "218m 41s (- 4155m 1s) (1 28%) 6.3176\n",
      "226m 41s (- 4307m 8s) (1 29%) 6.0606\n",
      "234m 48s (- 4461m 18s) (1 30%) 6.1767\n",
      "242m 53s (- 4614m 57s) (1 32%) 5.9529\n",
      "251m 0s (- 4769m 16s) (1 33%) 6.1083\n",
      "259m 10s (- 4924m 11s) (1 34%) 6.0073\n",
      "267m 17s (- 5078m 26s) (1 35%) 5.9876\n",
      "275m 19s (- 5231m 19s) (1 36%) 5.9080\n",
      "283m 30s (- 5386m 44s) (1 37%) 6.0335\n",
      "291m 36s (- 5540m 32s) (1 38%) 5.9553\n",
      "299m 40s (- 5693m 49s) (1 39%) 5.9771\n",
      "307m 48s (- 5848m 14s) (1 40%) 5.9986\n",
      "315m 55s (- 6002m 33s) (1 41%) 6.4290\n",
      "324m 3s (- 6156m 59s) (1 42%) 5.9912\n",
      "332m 5s (- 6309m 43s) (1 43%) 5.9469\n",
      "340m 9s (- 6463m 5s) (1 44%) 5.8047\n",
      "348m 15s (- 6616m 57s) (1 45%) 5.8216\n",
      "356m 25s (- 6771m 56s) (1 46%) 5.8641\n",
      "364m 30s (- 6925m 34s) (1 48%) 5.8517\n",
      "372m 32s (- 7078m 9s) (1 49%) 5.8392\n",
      "380m 40s (- 7232m 41s) (1 50%) 5.8890\n",
      "388m 47s (- 7387m 5s) (1 51%) 5.9533\n",
      "396m 53s (- 7540m 50s) (1 52%) 5.9592\n",
      "404m 56s (- 7693m 55s) (1 53%) 5.9677\n",
      "413m 4s (- 7848m 27s) (1 54%) 5.9419\n",
      "421m 16s (- 8004m 6s) (1 55%) 6.0965\n",
      "429m 23s (- 8158m 21s) (1 56%) 6.2193\n",
      "437m 29s (- 8312m 18s) (1 57%) 6.3538\n",
      "445m 34s (- 8465m 57s) (1 58%) 5.8941\n",
      "453m 39s (- 8619m 39s) (1 59%) 5.9532\n",
      "461m 49s (- 8774m 47s) (1 60%) 5.8066\n",
      "469m 53s (- 8927m 56s) (1 61%) 5.8723\n",
      "478m 3s (- 9082m 57s) (1 62%) 5.9250\n",
      "486m 4s (- 9235m 33s) (1 64%) 5.7200\n",
      "494m 9s (- 9388m 58s) (1 65%) 5.8023\n",
      "502m 15s (- 9542m 54s) (1 66%) 5.9364\n",
      "510m 24s (- 9697m 37s) (1 67%) 5.6785\n",
      "518m 28s (- 9851m 8s) (1 68%) 5.7641\n",
      "526m 35s (- 10005m 18s) (1 69%) 5.7692\n",
      "534m 43s (- 10159m 44s) (1 70%) 5.6276\n",
      "542m 49s (- 10313m 44s) (1 71%) 5.6807\n",
      "550m 57s (- 10468m 3s) (1 72%) 5.6261\n",
      "559m 2s (- 10621m 53s) (1 73%) 5.6835\n",
      "567m 8s (- 10775m 48s) (1 74%) 5.6586\n",
      "575m 11s (- 10928m 38s) (1 75%) 5.6508\n",
      "583m 20s (- 11083m 34s) (1 76%) 5.8216\n",
      "591m 28s (- 11237m 53s) (1 77%) 5.7173\n",
      "599m 37s (- 11392m 43s) (1 78%) 5.6408\n",
      "607m 50s (- 11548m 53s) (1 80%) 5.8705\n",
      "615m 58s (- 11703m 32s) (1 81%) 5.6069\n",
      "624m 8s (- 11858m 41s) (1 82%) 5.6534\n",
      "632m 20s (- 12014m 21s) (1 83%) 5.8384\n",
      "640m 27s (- 12168m 38s) (1 84%) 5.5568\n",
      "648m 33s (- 12322m 29s) (1 85%) 5.5994\n",
      "656m 41s (- 12477m 11s) (1 86%) 5.6357\n",
      "664m 52s (- 12632m 36s) (1 87%) 5.5968\n",
      "672m 59s (- 12786m 55s) (1 88%) 5.7815\n",
      "681m 5s (- 12940m 51s) (1 89%) 5.6839\n",
      "689m 13s (- 13095m 20s) (1 90%) 5.5031\n",
      "697m 24s (- 13250m 39s) (1 91%) 5.4661\n",
      "705m 33s (- 13405m 40s) (1 92%) 5.5128\n",
      "713m 39s (- 13559m 38s) (1 93%) 5.5081\n",
      "721m 45s (- 13713m 16s) (1 94%) 5.6012\n",
      "729m 51s (- 13867m 15s) (1 96%) 5.7021\n",
      "738m 0s (- 14022m 2s) (1 97%) 5.5434\n",
      "746m 9s (- 14176m 58s) (1 98%) 5.5919\n",
      "754m 19s (- 14332m 11s) (1 99%) 5.5686\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "_indices not supported on torch.LongTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-c79d1665c1fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# Run the train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0minput_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_matrix\u001b[0m\u001b[0;34m,\u001b[0m                     \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: _indices not supported on torch.LongTensor"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs): \n",
    "    # Shuffle data\n",
    "    #id_aux = np.random.permutation(np.arange(len(pairs_train)))\n",
    "    #pairs_train = pairs_train[id_aux]\n",
    "    \n",
    "    # Get the batches for this epoch\n",
    "    input_batches, input_matrixes, target_batches = generate_batches(input_lang, output_lang, 1, pairs_train, arr_dep=matrixes_train, USE_CUDA=USE_CUDA)    \n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    gcn.train()\n",
    "        \n",
    "    for batch_ix, (input_var, input_matrix, target_var) in enumerate(zip(input_batches, input_matrixes, target_batches)):\n",
    "        \n",
    "        # Run the train function\n",
    "        input_matrix = np.array(input_matrix[0])\n",
    "        degree = np.array(np.sum(input_matrix, axis=0))\n",
    "        degree = np.matrix(np.diag(degree))\n",
    "        \n",
    "        input_matrix = torch.FloatTensor(np.linalg.inv(degree) * input_matrix)\n",
    "\n",
    "        loss = train(input_var, target_var, input_matrix,\\\n",
    "                 encoder, decoder, gcn, criterion, batch_ix, train=True)\n",
    "        #loss = train_luong(input_var, target_var, input_var.size(1), True)\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Keep track of loss\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if batch_ix == 0: continue            \n",
    "\n",
    "        if batch_ix % (print_every * batch_size)  == 0:\n",
    "            print_loss_avg = print_loss_total / (print_every * batch_size)\n",
    "            print_loss_total = 0\n",
    "            print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, batch_ix / len(input_batches) * 100, print_loss_avg)\n",
    "            train_losses.append(loss)\n",
    "            print(print_summary)\n",
    "    \n",
    "    input_batches, input_matrixes, target_batches = generate_batches(input_lang, output_lang, 1, pairs_test, arr_dep=matrixes_test, USE_CUDA=USE_CUDA)\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    gcn.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        print_loss_total = 0\n",
    "        for batch_ix, (input_var, input_matrix, target_var) in enumerate(zip(input_batches, input_matrixes, target_batches)):\n",
    "    \n",
    "            # Run the train function\n",
    "            input_matrix = np.array(input_matrix[0])\n",
    "            degree = np.array(np.sum(input_matrix, axis=0))\n",
    "            degree = np.matrix(np.diag(degree))\n",
    "\n",
    "            input_matrix = torch.FloatTensor(np.linalg.inv(degree) * input_matrix)\n",
    "            loss = train(input_var, target_var, input_matrix,\\\n",
    "                     encoder, decoder, gcn, criterion, batch_ix, train=False)\n",
    "\n",
    "            print_loss_total += loss\n",
    "            torch.cuda.empty_cache()\n",
    "    val_loss = print_loss_total / len(input_batches)\n",
    "    validation_losses.append(val_loss)\n",
    "    # Evaluating Bleu\n",
    "    #evaluator = Evaluator(encoder, decoder, input_lang, output_lang, MAX_LENGTH, True)\n",
    "    #candidates, references = evaluator.get_candidates_and_references(pairs_test, k_beams=1)\n",
    "    #bleu = BLEU(candidates, [references])\n",
    "    #if bleu[0] > best_bleu:\n",
    "    #    best_bleu = bleu[0]\n",
    "    #    torch.save(encoder.state_dict(), f'{DIR_RESULTS}/encoder.pkl')\n",
    "    #    torch.save(decoder.state_dict(), f'{DIR_RESULTS}/decoder.pkl')\n",
    "    #validation_bleu.append(bleu)\n",
    "    print(f'val_loss: {val_loss:.4f} - bleu: {0}')\n",
    "\n",
    "    # Prevent overflow gpu memory\n",
    "    #del evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0., 1., 0., 0., 1., 1.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 6. 2. 2. 2. 5. 2. 3. 2. 2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[2., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 6., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 2., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 2., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 2., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 5., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 3., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 2., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.array(np.sum(temp, axis=0))\n",
    "print(D)\n",
    "D = np.matrix(np.diag(D))\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.16666667, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.2       , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.5       , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.33333333, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.5       , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.5       ]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D**-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.16666667, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.2       , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.5       , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.33333333, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.5       , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.5       ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(temp, np.linalg.inv(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5       , 0.5       , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.16666667, 0.16666667, 0.16666667, 0.        , 0.        ,\n",
       "         0.16666667, 0.        , 0.        , 0.16666667, 0.16666667],\n",
       "        [0.        , 0.5       , 0.5       , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "         0.5       , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
       "         0.5       , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.2       , 0.        , 0.2       , 0.2       ,\n",
       "         0.2       , 0.        , 0.2       , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.5       , 0.5       , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.33333333, 0.33333333, 0.33333333, 0.        , 0.        ],\n",
       "        [0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.5       , 0.        ],\n",
       "        [0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.5       ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D**-1*temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 1]), (7, 7))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 0\n",
    "input_batches[ix].shape, input_matrixes[ix][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 7])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he gave me 10 ,000 yen . <eos>'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([input_lang.vocab.itos[w] for w in input_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(encoder, decoder, input_lang, output_lang, \n",
    "                      MAX_LENGTH, USE_CUDA)\n",
    "candidates, references = evaluator.get_candidates_and_references(pairs_test[:10000], k_beams=2)\n",
    "len(candidates), len(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28063523097173265,\n",
       " [0.6573135078342698,\n",
       "  0.37567686039915427,\n",
       "  0.22488307382629802,\n",
       "  0.13494545201862276],\n",
       " 0.953820572858132)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEU(candidates, [references]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.041672706604004,\n",
       " 7.149496555328369,\n",
       " 14.810012817382812,\n",
       " 12.101698875427246,\n",
       " 9.06682014465332,\n",
       " 7.260944366455078,\n",
       " 6.044005393981934,\n",
       " 6.0010833740234375,\n",
       " 7.1673264503479,\n",
       " 6.06639289855957,\n",
       " 6.229933261871338,\n",
       " 8.623738288879395,\n",
       " 5.882908344268799,\n",
       " 4.927737236022949,\n",
       " 5.671040058135986,\n",
       " 7.489520072937012,\n",
       " 5.501565456390381,\n",
       " 5.914140224456787,\n",
       " 6.912267208099365,\n",
       " 6.224165916442871,\n",
       " 7.6937079429626465,\n",
       " 6.377658843994141,\n",
       " 8.010522842407227,\n",
       " 8.193879127502441,\n",
       " 7.284544944763184,\n",
       " 4.864162445068359,\n",
       " 6.447579860687256,\n",
       " 6.805881977081299,\n",
       " 5.03970193862915,\n",
       " 6.144567012786865,\n",
       " 5.522188186645508,\n",
       " 6.3946533203125,\n",
       " 7.317024230957031,\n",
       " 7.084739685058594,\n",
       " 4.866414546966553,\n",
       " 4.8789286613464355,\n",
       " 6.360021114349365,\n",
       " 5.258521556854248,\n",
       " 7.594843864440918,\n",
       " 5.99109411239624,\n",
       " 6.1218085289001465,\n",
       " 4.6263885498046875,\n",
       " 6.505831241607666,\n",
       " 6.49678897857666,\n",
       " 6.661844253540039,\n",
       " 5.703457832336426,\n",
       " 6.080120086669922,\n",
       " 5.556210994720459,\n",
       " 4.3718485832214355,\n",
       " 7.616245269775391,\n",
       " 5.660667896270752,\n",
       " 4.477021217346191,\n",
       " 5.971453666687012,\n",
       " 7.151060581207275,\n",
       " 7.284686088562012,\n",
       " 4.710358619689941,\n",
       " 5.699878692626953,\n",
       " 5.8283185958862305,\n",
       " 5.429839134216309,\n",
       " 5.627746105194092,\n",
       " 8.024958610534668,\n",
       " 7.326678276062012,\n",
       " 6.238666534423828,\n",
       " 4.728693962097168,\n",
       " 6.361328125,\n",
       " 5.92225456237793,\n",
       " 6.291927337646484,\n",
       " 6.011835098266602,\n",
       " 7.155662536621094,\n",
       " 5.337331295013428,\n",
       " 7.359513282775879,\n",
       " 6.708942890167236,\n",
       " 6.291254997253418,\n",
       " 6.5870819091796875,\n",
       " 6.9649858474731445,\n",
       " 5.453511714935303,\n",
       " 5.605909824371338,\n",
       " 6.4293036460876465,\n",
       " 6.750390529632568,\n",
       " 8.476428031921387,\n",
       " 5.792107582092285,\n",
       " 7.52388334274292,\n",
       " 5.88793420791626,\n",
       " 5.64914083480835,\n",
       " 5.583569049835205,\n",
       " 7.05214786529541,\n",
       " 7.007693767547607,\n",
       " 6.556692600250244,\n",
       " 5.914644241333008,\n",
       " 7.384115219116211,\n",
       " 6.446426868438721,\n",
       " 5.6869215965271,\n",
       " 6.317768573760986,\n",
       " 6.537539958953857,\n",
       " 8.257403373718262,\n",
       " 6.223647594451904,\n",
       " 7.760086536407471,\n",
       " 6.339871883392334,\n",
       " 6.288576602935791,\n",
       " 6.117007732391357,\n",
       " 4.761729717254639,\n",
       " 5.098626136779785,\n",
       " 5.2466816902160645,\n",
       " 4.348966121673584,\n",
       " 6.218953609466553,\n",
       " 4.525362968444824,\n",
       " 8.28030014038086,\n",
       " 5.524833679199219,\n",
       " 7.029933452606201,\n",
       " 5.692931175231934,\n",
       " 5.107240200042725,\n",
       " 7.430395126342773,\n",
       " 6.536320686340332,\n",
       " 6.89471960067749,\n",
       " 4.141633987426758,\n",
       " 5.832042217254639,\n",
       " 5.386961460113525,\n",
       " 5.803618907928467,\n",
       " 6.419718265533447,\n",
       " 6.172667503356934,\n",
       " 7.619015216827393,\n",
       " 6.166060447692871,\n",
       " 6.7607011795043945,\n",
       " 5.820564270019531,\n",
       " 6.111392021179199,\n",
       " 4.593202114105225,\n",
       " 6.3956732749938965,\n",
       " 4.5033745765686035,\n",
       " 5.831901550292969,\n",
       " 6.683056354522705,\n",
       " 6.531650543212891,\n",
       " 4.357241630554199,\n",
       " 6.526559829711914,\n",
       " 5.965932369232178,\n",
       " 7.174294948577881,\n",
       " 5.76188325881958,\n",
       " 5.928871154785156,\n",
       " 6.473082542419434,\n",
       " 6.172927379608154,\n",
       " 6.565548896789551]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"tom wasn 't convinced it was a good idea .\",\n",
       "       'tom no estaba convencido de que fuera una buena idea .'],\n",
       "      dtype='<U245')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_test[480]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['just act as if nothing has happened .',\n",
       "       'haga de cuenta que nada ha ocurrido .'],\n",
       "      dtype='<U245')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_train[80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
